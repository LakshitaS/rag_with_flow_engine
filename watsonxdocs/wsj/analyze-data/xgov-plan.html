<!DOCTYPE html><html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="DC.Publisher" content="IBM Corporation">
  <meta name="DC.rights" content="Â© Copyright IBM Corporation {{ copyright.years }}">
  <meta name="IBM.Country" content="ZZ">
  <meta name="DC.Date" content="{{ lastupdated }}">
  <meta name="keywords" content="{{ keywords }}">
  <meta name="subcollection" content="{{ subcollection }}">
  <meta name="description" content="Plan how to use watsonx.governance to accelerate responsible, transparent, and explainable AI workflows with an AI governance solution that provides end-to-end monitoring for machine learning and generative AI models.">
  <meta name="content.type" content="topic">
  <meta name="tags" content="{{ services }}">
  <meta name="account.plan" content="{{ account-plan }}">
  <meta name="completion.time" content="{{ completion-time }}">
  <meta name="version" content="{{ version }}">
  <meta name="deployment.url" content="{{ deployment-url }}">
  <meta name="industry" content="{{ industry }}">
  <meta name="compliance" content="{{ compliance }}">
  <meta name="use.case" content="{{ use-case }}">
  <meta name="source.format" content="markdown">




  <!-- Licensed Materials - Property of IBM -->
  <!-- US Government Users Restricted Rights -->
  <!-- Use, duplication or disclosure restricted by -->
  <!-- GSA ADP Schedule Contract with IBM Corp. -->

  <title>Planning for AI governance</title>
<link rel="canonical" href="https://www.ibm.com/docs/en/watsonx-as-a-service?topic=assets-planning-governance"><meta name="viewport" content="width=device-width,initial-scale=1"></head>

<body>
  <main role="main">
    <article aria-labelledby="planning-for-ai-governance" role="article">
      <style>
        .midd::after {
          content: "\A\00A0\00A0";
          white-space: pre
        }
      </style>
      <section id="section-planning-for-ai-governance">
        <h1 id="planning-for-ai-governance">Planning for AI governance</h1>
        <p>Plan how to use watsonx.governance to accelerate responsible, transparent, and explainable AI workflows with an AI governance solution that provides end-to-end monitoring for machine learning and generative AI models.</p>
        <section id="section-governance-capabilities">
          <h2 id="governance-capabilities">Governance capabilities</h2>
          <div class="note note"><span class="notetitle">Note:</span>
            <md-block>
              <p>To govern metadata from foundation models curated by IBM, you must have watsonx.ai provisioned.</p>
              <p></p>
            </md-block>
          </div>
          <p></p>
          <p>Consider these watsonx.governance capabilities as you plan your governance strategy:</p>
          <ul>
            <li>Collect metadata in factsheets about machine learning models and prompt templates for generative AI foundation models.</li>
            <li>Monitor machine learning deployments for fairness, drift, and quality to ensure that your models are meeting specified standards.</li>
            <li>Monitor generative AI assets for breaches of toxic language thresholds or detection of personal identifiable information.</li>
            <li>Evaluate prompt templates with metrics designed to measure performance and to test for the presence of prohibited content, such as hateful speech.</li>
            <li>Collect model health data that includes data size, latency, and throughput to help you assess performance issues and manage resource consumption.</li>
            <li>Use the <a href="../ai-risk-atlas/ai-risk-atlas.html">AI risk atlas</a> as a guide to the challenges of AI solutions so you can plan risk mitigation and meet your compliance and regulatory goals.</li>
            <li>Assign a single risk score to tracked models to indicate the relative impact of the associated model. For example, a model that predicts sensitive information such as a credit score might be assigned a high risk score.</li>
            <li>Use the automated transaction analysis tools to improve transparency and explainability for your AI assets. For example, see how a feature contributes to a prediction and test what-if scenarios to explore different outcomes.</li>
            <li>Optionally integrate with <strong>IBM OpenPages Model Risk Governance</strong> to collect metadata about foundation models as well as machine learning models to help you achieve your governance goals. You can also use OpenPages to develop
              workflows that support your governance processes.</li>
          </ul>
        </section>
        <section id="section-planning-for-governance">
          <h2 id="planning-for-governance">Planning for governance</h2>
          <p>Consider these governance strategies:</p>
          <ul>
            <li><a href="#people">Build your governance team</a></li>
            <li><a href="#structure">Set up your governance structures</a></li>
            <li><a href="#collab">Manage collaboration with roles and access control</a></li>
            <li><a href="#communicate">Develop a communication plan</a></li>
            <li><a href="#simple">Implement a simple solution</a></li>
            <li><a href="#complex">Plan for more complex solutions</a></li>
          </ul>
          <section id="section-people">
            <h3 id="people">Build a governance team</h3>
            <p>Consider the expertise that you need on your governance team. A typical governance plan might include the following roles. Sometimes, the same person might fill multiple roles. In other cases, a role might represent a team of people.</p>
            <ul>
              <li><strong>Model owner</strong>: The owner creates an AI use case to track a solution to a business need. The owner requests the model or prompt template, manages the approval process, and tracks the solution through the AI Lifecycle.</li>
              <li><strong>Model developer or Data scientist</strong>: The developer works with the data in a data set or a large language model (LLM) and creates the machine learning model or LLM prompt template.</li>
              <li><strong>Model validator</strong>: the validator tests the solution to determine whether it meets the goals that are stated in the AI use case.</li>
              <li><strong>Risk and compliance manager</strong>: The risk manager determines the policies and compliance thresholds for the AI use case. For example, the risk manager might determine the rules to apply for testing a solution for fairness or
                for screening output for hateful and abusive speech.</li>
              <li><strong>MLOps engineer</strong>: The MLOps engineer moves a solution from a pre-production (test) environment to a production environment when a solution is deemed ready to be fully deployed.</li>
              <li><strong>App developer</strong>: Following deployment, and app developer runs evaluations against the deployment to monitor how the solution performs against the metric threshold set by the risk and compliance owner. If performance drops
                below specified thresholds, the app developer works with the other stakeholders to address problems and update the model or prompt template.</li>
            </ul>
          </section>
          <section id="section-structure">
            <h3 id="structure">Set up a governance structure</h3>
            <p>After you identify roles and assembling a team, plan your governance structure.</p>
            <ol>
              <li>Create an inventory for storing AI use cases. An inventory is where you store and view AI use cases and the factsheets that are associated with the governed assets. Depending on your governance requirements, store all use cases in a single
                inventory, or create multiple inventories for your governance efforts.</li>
              <li>Create projects for collaboration. If you are using IBM tools, create a Watson Studio project. The project can hold the data that is required to train or test the AI solution and the model or prompt template that is governed. Use the access
                control to restrict access to the approved collaborators.</li>
              <li>Create a pre-production deployment space. Use the space to test your model or prompt template by using test data. Like a project, a space provides access control features so you can include the required collaborators.</li>
              <li>Configure test and validation evaluations. Provide the model or prompt template details and configure a set of evaluations to test the performance of your solution. For example, you might test a machine learning model for dimensions such
                as fairness, quality, and drift, and test a prompt template against metrics such as perplexity (how accurate the output is), or toxicity (whether the output contains hateful or abusive speech). By testing on known (labeled) data, you can
                evaluate the performance before you move a solution to production.</li>
              <li>Configure a production space. When the model or prompt template is ready to be deployed to a production environment, move the solution and all dependencies to a production space. A production space typically has a tighter access control
                list.</li>
              <li>Configure evaluations for the deployed model. Provide the model details and configure evaluations for the solution. You can now test against live data rather than test data. It is important to monitor your solution so that you are alerted
                if thresholds are crossed, indicating a potential problem with the deployed solution.</li>
            </ol>
          </section>
          <section id="section-collab">
            <h3 id="collab">Manage collaboration for governance</h3>
            <p>Watsonx.governance is built on a collaborative platform to allow for all approved team members to contribute to the goals of solving business problems.</p>
            <p>To plan for collaboration, consider how to manage access to the inventories, projects, and spaces you use for governance.</p>
            <p>Use roles along with access control features to ensure that your team has appropriate access to meet goals.</p>
          </section>
          <section id="section-communicate">
            <h3 id="communicate">Develop a communication plan</h3>
            <p>Some of the workflow around defining an AI use case and moving assets through the lifecycle rely on effective communication. Decide how your team will communicate and establish the details. For example:</p>
            <ul>
              <li>Will you use email for decision-making or a messaging tool such as Slack?</li>
              <li>Is there a formal process for adding comments to an asset as it moves through a workflow?</li>
            </ul>
            <p>Create your communication plan and share it with your team.</p>
          </section>
          <section id="section-simple">
            <h3 id="simple">Implement a simple governance solution</h3>
            <p>As you roll out your governance strategy, start with a simple implementation, then consider how to build incrementally to a more comprehensive solution. The simplest implementation requires an AI use case in an inventory, with an asset moving
              from request to production.</p>
            <p>For the most straightforward implementation of AI governance, create an AI use case for tracking assets. An AI use case in an inventory consists of a set of factsheets containing lineage, history, and other relevant information about a model's
              lifecycle. Add data scientists, data engineers, and other users as collaborators.</p>
            <p><img src="images/xgov-simple.svg" alt="Inventories store factsheets with metadata about governed assets" height="400px"></p>
            <p>AI use case owners can request and track assets:</p>
            <ul>
              <li>Business users create AI use cases in the inventory to request machine-learning models or LLM prompt templates.</li>
              <li>Data scientists associate the trained asset with an AI use case to track lifecycle activities.</li>
            </ul>
            <p>AI factsheets accumulate information about the model or prompt templates in the following ways:</p>
            <ul>
              <li>All actions that are associated with the tracked asset are automatically saved, including deployments and evaluations.</li>
              <li>All changes to input data assets are automatically saved.</li>
              <li>Data scientists can add tags, supporting documentation, and other information.</li>
              <li>Data scientists can associate challenger models with the AI use cases to compare model performance.</li>
            </ul>
            <p>Validators and other stakeholders review AI factsheets to ensure compliance and certify asset progress from development to production. They can also generate reports from the factsheets to print, share, or archive details.</p>
          </section>
          <section id="section-complex">
            <h3 id="complex">Plan for more complex solutions</h3>
            <p>You can extend your AI governance implementation at any time. Consider these options to extend governance:</p>
            <ul>
              <li>MLOps engineers can extend model tracking to include external models that are created with third-party machine learning models.</li>
              <li>MLOps engineers can add custom properties to factsheets to track more information.</li>
              <li>Compliance analysts can customize the default report templates to generate tailored reports for the organization.</li>
            </ul>
          </section>
        </section>
        <section id="section-governing-assets-that-are-created-locally-or-externally">
          <h2 id="governing-assets-that-are-created-locally-or-externally">Governing assets that are created locally or externally</h2>
          <p>Watsonx.governance provides the tools for you to govern assets you created using IBM tools, such as machine learning models created by using AutoAI or foundation model prompt templates created in a watsonx project. You can also govern machine
            learning models that are created by using non-IBM tools, such as Microsoft Azure or Amazon Web Services. As you develop your governance plan, consider these differences:</p>
          <ul>
            <li>IBM assets developed with tools such as Watson Studio are available for governance earlier in the lifecycle. You can track the factsheet for a local asset from the Development phase, and have visibility into details such as the training data
              and creation details from an earlier stage.</li>
            <li>An inventory owner or administrator must enable governance for external models.</li>
            <li>When governance is enabled for external models, they can be added to an AI use case explicitly. If you track an external model in the develop phase, then lifecycle activities for the validate and operate phases are tracked automatically.</li>
          </ul>
          <p>For a list of supported machine learning model providers, see <a href="../model/wos-frameworks-ovr.html">Supported machine learning providers</a>.</p>
        </section>
        <section id="section-next-steps">
          <h2 id="next-steps">Next steps</h2>
          <p>To begin governance, follow the steps in <a href="../model/wos-provision-launch.html">Provisioning and launching IBM watsonx.governance</a> to provision Watson OpenScale with AI Factsheets.</p>
          <p><strong>Parent topic:</strong> <a href="xgov-overview.html">Watsonx.governance overview</a></p>
        </section>
      </section>
    </article>
  </main>

<script type="text/javascript"  src="/DEWsG3/JOI980/yQyM/iRupUf/mVarA/YDJa4kXtLhb7/LwkITClvAg/Wgkg/WmBVIDs"></script><link rel="stylesheet" type="text/css"  href="/_sec/cp_challenge/sec-4-4.css">
                                        <script  src="/_sec/cp_challenge/sec-cpt-4-4.js" async defer></script>
                                        <div id="sec-overlay" style="display:none;">
                                        <div id="sec-container">
                                        </div>
                                      </div></body></html>