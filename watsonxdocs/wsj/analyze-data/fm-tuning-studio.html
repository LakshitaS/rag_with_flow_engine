<!DOCTYPE html><html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="DC.Publisher" content="IBM Corporation">
  <meta name="DC.rights" content="Â© Copyright IBM Corporation {{ copyright.years }}">
  <meta name="IBM.Country" content="ZZ">
  <meta name="DC.Date" content="{{ lastupdated }}">
  <meta name="keywords" content="{{ keywords }}">
  <meta name="subcollection" content="{{ subcollection }}">
  <meta name="description" content="Tune a foundation model with the Tuning Studio to guide an AI foundation model to return useful output.">
  <meta name="content.type" content="topic">
  <meta name="tags" content="{{ services }}">
  <meta name="account.plan" content="{{ account-plan }}">
  <meta name="completion.time" content="{{ completion-time }}">
  <meta name="version" content="{{ version }}">
  <meta name="deployment.url" content="{{ deployment-url }}">
  <meta name="industry" content="{{ industry }}">
  <meta name="compliance" content="{{ compliance }}">
  <meta name="use.case" content="{{ use-case }}">
  <meta name="source.format" content="markdown">




  <!-- Licensed Materials - Property of IBM -->
  <!-- US Government Users Restricted Rights -->
  <!-- Use, duplication or disclosure restricted by -->
  <!-- GSA ADP Schedule Contract with IBM Corp. -->

  <title>Tuning Studio</title>
<link rel="canonical" href="https://www.ibm.com/docs/en/watsonx-as-a-service?topic=solutions-tuning-studio"><meta name="viewport" content="width=device-width,initial-scale=1"></head>

<body>
  <main role="main">
    <article aria-labelledby="tuning-studio" role="article">
      <style>
        .midd::after {
          content: "\A\00A0\00A0";
          white-space: pre
        }
      </style>
      <section id="section-tuning-studio">
        <h1 id="tuning-studio">Tuning Studio</h1>
        <p>Tune a foundation model with the Tuning Studio to guide an AI foundation model to return useful output.</p>
        <dl>
          <dt><strong>Required permissions</strong></dt>
          <dd>
            <p>To run training experiments, you must have the <strong>Admin</strong> or <strong>Editor</strong> role in a project.</p>
          </dd>
          <dd>
            <p>The Tuning Studio is not available with all plans or in all data centers. See <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a> and <a href="../getting-started/regional-datactr.html">Regional availability for services and features</a>.</p>
          </dd>
          <dt><strong>Data format</strong></dt>
          <dd>
            <p>Tabular: JSON, JSONL. For details, see <a href="fm-tuning-data.html">Data formats</a>.</p>
          </dd>
        </dl>
        <div class="note note"><span class="notetitle">Note:</span> You can use the same training data file with one or more tuning experiments.</div>
        <dl>
          <dt><strong>Data size</strong></dt>
          <dd>50 to 10,000 input and output example pairs. The maximum file size is 200 MB.</dd>
        </dl>
        <p>You use the Tuning Studio to create a tuned version of an existing foundation model.</p>
        <p>&nbsp;</p>
        <p>Watch a video that explains when and why to tune a foundation model.</p>
        <div>
          <p style="font-size:smaller">This video provides a visual method to learn the concepts and tasks in this documentation.</p><iframe id="wm-wx-why-tune" src="https://video.ibm.com/embed/channel/23952663/video/wx-why-tune" lang="en-US" style="border: 0;" webkitallowfullscreen="" allowfullscreen="" frameborder="no" width="560" height="315" title="This video explain when and why to tune foundation models by using the Tuning Studio." alt="This video explain when and why to tune foundation models by using the Tuning Studio."></iframe></div>
        <p>&nbsp;</p>
        <p>Foundation models are AI models that are pretrained on terabytes of data from across the internet and other public resources. They are unrivaled in their ability to predict the next best word and generate language. While language-generation can
          be useful for brainstorming and spurring creativity, foundation models typically need to be guided to achieve concrete tasks. Model tuning, and other techniques, such as retrieval-augmented generation, help you to use foundation models in meaningful
          ways for your business.</p>
        <p>With the Tuning Studio, you can tune a smaller foundation model to improve its performance on natural language processing tasks such as classification, summarization, and generation. Tuning can help a smaller foundation model achieve results comparable
          to larger models in the same model family. By tuning and deploying the smaller model, you can reduce long-term inference costs.</p>
        <p>Much like prompt engineering, tuning a foundation model helps you to influence the content and format of the foundation model output. Knowing what to expect from a foundation model is essential if you want to plug the step of inferencing a foundation
          model into a business workflow.</p>
        <p>The following diagram illustrates how tuning a foundation model can help you guide the model to generate useful output. You provide labeled data that illustrates the format and type of output that you want the model to return, which helps the
          foundation model to follow the established pattern.</p>
        <p><img src="images/fm-tune-overview.svg" alt="How a tuned model relates to a foundation model" style="max-width:90%;height:auto;width:auto"></p>
        <p>You can tune a foundation model to optimize the model's ability to do many things, including:</p>
        <ul>
          <li>Generate new text in a specific style</li>
          <li>Generate text that summarizes or extracts information in a certain way</li>
          <li>Classify text</li>
        </ul>
        <p>To learn more about when tuning a model is the right approach, see <a href="fm-tuning-when.html">When to tune a foundation model</a>.</p>
        <section id="section-workflow">
          <h2 id="workflow">Workflow</h2>
          <p>Tuning a model involves the following tasks:</p>
          <ol>
            <li>
              <p>Engineer prompts that work well with the model you want to use.</p>
              <ul>
                <li>Find the largest foundation model that works best for the task.</li>
                <li>Experiment until you understand which prompt formats show the most potential for getting good results from the model.</li>
              </ul>
              <p>Tuning doesn't mean you can skip prompt engineering altogether. Experimentation is necessary to find the right foundation model for your use case. Tuning means you can do the work of prompt engineering once and benefit from it again and
                again.</p>
              <p>You can use the Prompt Lab to experiment with prompt engineering. For help, see <a href="fm-prompt-lab.html">Prompt Lab</a>.</p>
            </li>
            <li>
              <p>Create training data to use for model tuning.</p>
            </li>
            <li>
              <p>Create a tuning experiment to tune the model.</p>
            </li>
            <li>
              <p>Evaluate the tuned model.</p>
              <p>If necessary, change the training data or the experiment parameters and run more experiments until you're satisfied with the results.</p>
            </li>
            <li>
              <p>Deploy the tuned model.</p>
            </li>
            <li>
              <p>Submit inference requests to the tuned model.</p>
            </li>
          </ol>
        </section>
        <section id="section-foundation-model-tuning-costs">
          <h2 id="foundation-model-tuning-costs">Foundation model tuning costs</h2>
          <p>The cost of tuning a foundation model is measured in capacity unit hours, which measures the compute resource consumption of the tuning experiment. For more information, see <a href="../getting-started/wml-plans.html#cuh-metering">Capacity Unit Hours metering</a>.</p>
          <p>The cost of inferencing a tuned model is measured in resource units. The rate depends on the model's billing class. A prompt-tuned foundation model has the same billing class as the foundation model that it tunes. For more information, see
            <a href="../getting-started/wml-plans.html#ru-metering">Resource unit metering</a>.</p>
        </section>
        <section id="section-learn-more">
          <h2 id="learn-more">Learn more</h2>
          <ul>
            <li><a href="fm-tuning-when.html">When to tune</a></li>
            <li><a href="fm-tuning-methods.html">Methods for tuning</a></li>
            <li><a href="fm-tuning-model-choose.html">Choosing a foundation model to tune</a></li>
            <li><a href="fm-tuning-tune.html">Tuning a model</a></li>
            <li><a href="fm-tuning-methodology.html">Evaluate the results of a tuning experiment</a></li>
          </ul>
        </section>
        <section id="section-get-started">
          <h2 id="get-started">Get started</h2>
          <ul>
            <li><a href="../getting-started/get-started-tuning-studio.html">Quick start: Tune a foundation model</a></li>
            <li><a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/bf57e8896f3e50c638b5a378780f7502" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Sample notebook: Tune a model to classify CFPB documents in watsonx</a></li>
            <li><a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/1a8e5c23-1dc0-4f6e-b67f-eaac343a11f8?context=wx" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Sample notebook: Prompt tuning for multi-class classification with watsonx</a></li>
          </ul>
          <p><strong>Parent topic:</strong> <a href="fm-overview.html">Developing generative AI solutions</a></p>
        </section>
      </section>
    </article>
  </main>

<script type="text/javascript"  src="/DEWsG3/JOI980/yQyM/iRupUf/mVarA/YDJa4kXtLhb7/LwkITClvAg/Wgkg/WmBVIDs"></script><link rel="stylesheet" type="text/css"  href="/_sec/cp_challenge/sec-4-4.css">
                                        <script  src="/_sec/cp_challenge/sec-cpt-4-4.js" async defer></script>
                                        <div id="sec-overlay" style="display:none;">
                                        <div id="sec-container">
                                        </div>
                                      </div></body></html>