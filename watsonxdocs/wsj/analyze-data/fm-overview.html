<!DOCTYPE html><html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="DC.Publisher" content="IBM Corporation">
  <meta name="DC.rights" content="Â© Copyright IBM Corporation {{ copyright.years }}">
  <meta name="IBM.Country" content="ZZ">
  <meta name="DC.Date" content="{{ lastupdated }}">
  <meta name="keywords" content="{{ keywords }}">
  <meta name="subcollection" content="{{ subcollection }}">
  <meta name="description" content="You can develop generative AI solutions with foundation models in IBM watsonx.ai. You can generate prompts to generate, classify, summarize, or extract content from your input text. Choose from IBM models or open source models from Hugging Face. You can tune foundation models to customize your prompt output or optimize inferencing performance.">
  <meta name="content.type" content="topic">
  <meta name="tags" content="{{ services }}">
  <meta name="account.plan" content="{{ account-plan }}">
  <meta name="completion.time" content="{{ completion-time }}">
  <meta name="version" content="{{ version }}">
  <meta name="deployment.url" content="{{ deployment-url }}">
  <meta name="industry" content="{{ industry }}">
  <meta name="compliance" content="{{ compliance }}">
  <meta name="use.case" content="{{ use-case }}">
  <meta name="source.format" content="markdown">




  <!-- Licensed Materials - Property of IBM -->
  <!-- US Government Users Restricted Rights -->
  <!-- Use, duplication or disclosure restricted by -->
  <!-- GSA ADP Schedule Contract with IBM Corp. -->

  <title>Developing generative AI solutions with foundation models</title>
<link rel="canonical" href="https://www.ibm.com/docs/en/watsonx-as-a-service?topic=developing-generative-ai-solutions"><meta name="viewport" content="width=device-width,initial-scale=1"></head>

<body>
  <main role="main">
    <article aria-labelledby="developing-generative-ai-solutions-with-foundation-models" role="article">
      <style>
        .midd::after {
          content: "\A\00A0\00A0";
          white-space: pre
        }
      </style>
      <section id="section-developing-generative-ai-solutions-with-foundation-models">
        <h1 id="developing-generative-ai-solutions-with-foundation-models">Developing generative AI solutions with foundation models</h1>
        <p>You can develop generative AI solutions with foundation models in IBM watsonx.ai. You can generate prompts to generate, classify, summarize, or extract content from your input text. Choose from IBM models or open source models from Hugging Face.
          You can tune foundation models to customize your prompt output or optimize inferencing performance.</p>
        <p>Foundation models are large AI models that have billions of parameters and are trained on terabytes of data. Foundation models can do various tasks, including text, code, or image generation, classification, conversation, and more. Large language
          models are a subset of foundation models that can do tasks related to text and code. Watsonx.ai has a range of deployed large language models for you to try. For details, see <a href="fm-models.html">Supported foundation models</a>.</p>
        <section id="section-foundation-model-architecture">
          <h2 id="foundation-model-architecture">Foundation model architecture</h2>
          <p>Foundation models represent a fundamentally different model architecture and purpose for AI systems. The following diagram illustrates the difference between traditional AI models and foundation models.</p>
          <p><img src="images/fm-overview-diagram.svg" alt="Comparison of traditional AI models to foundation models" style="max-width:90%;height:auto;width:auto"></p>
          <p>As shown in the diagram, traditional AI models specialize in specific tasks. Most traditional AI models are built by using machine learning, which requires a large, structured, well-labeled data set that encompasses a specific task that you
            want to tackle. Often these data sets must be sourced, curated, and labeled by hand, a job that requires people with domain knowledge and takes time. After it is trained, a traditional AI model can do a single task well. The traditional AI
            model uses what it learns from patterns in the training data to predict outcomes in unknown data. You can create machine learning models for your specific use cases with tools like AutoAI and Jupyter notebooks, and then deploy them.</p>
          <p>In contrast, foundation models are trained on large, diverse, unlabeled data sets and can be used for many different tasks. Foundation models were first used to generate text by calculating the most-probable next word in natural language translation
            tasks. However, model providers are learning that, when prompted with the right input, foundation models can do various other tasks well. Instead of creating your own foundation models, you use existing deployed models and engineer prompts
            to generate the results that you need.</p>
        </section>
        <section id="section-methods-of-working-with-foundation-models">
          <h2 id="methods-of-working-with-foundation-models">Methods of working with foundation models</h2>
          <p>The possibilities and applications of foundation models are just starting to be discovered. Explore and validate use cases with foundation models in watsonx.ai to automate, simplify, and speed up existing processes or provide value in a new
            way.</p>
          <p>You can interact with foundation models in the following ways:</p>
          <ul>
            <li>Engineer prompts and inference deployed foundation models directly by using the Prompt Lab</li>
            <li>Inference deployed foundation models programmatically by using the Python library</li>
            <li>Tune foundation models to return output in a certain style or format by using the Tuning Studio</li>
          </ul>
        </section>
        <section id="section-learn-more">
          <h2 id="learn-more">Learn more</h2>
          <ul>
            <li><a href="fm-prompt-lab.html">Prompt Lab</a></li>
            <li><a href="fm-tuning-studio.html">Tuning Studio</a></li>
            <li><a href="fm-code.html">Coding generative AI solutions</a></li>
            <li><a href="fm-security.html">Security and privacy</a></li>
            <li><a href="fm-disclaimer.html">Model terms of use</a></li>
            <li><a href="fm-tokens.html">Tokens</a></li>
            <li><a href="fm-rag.html">Retrieval-augmented generation</a></li>
            <li><a href="../ai-risk-atlas/ai-risk-atlas.html">AI risk atlas</a></li>
            <li><a href="../getting-started/quickstart-tutorials.html#prompt">Quick start tutorials: Working with generative AI</a></li>
          </ul>
        </section>
      </section>
    </article>
  </main>

<script type="text/javascript"  src="/DEWsG3/JOI980/yQyM/iRupUf/mVarA/YDJa4kXtLhb7/LwkITClvAg/Wgkg/WmBVIDs"></script><link rel="stylesheet" type="text/css"  href="/_sec/cp_challenge/sec-4-4.css">
                                        <script  src="/_sec/cp_challenge/sec-cpt-4-4.js" async defer></script>
                                        <div id="sec-overlay" style="display:none;">
                                        <div id="sec-container">
                                        </div>
                                      </div></body></html>