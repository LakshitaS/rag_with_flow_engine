<!DOCTYPE html><html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="DC.Publisher" content="IBM Corporation">
  <meta name="DC.rights" content="© Copyright IBM Corporation {{ copyright.years }}">
  <meta name="IBM.Country" content="ZZ">
  <meta name="DC.Date" content="{{ lastupdated }}">
  <meta name="keywords" content="{{ keywords }}">
  <meta name="subcollection" content="{{ subcollection }}">
  <meta name="description" content="Check back each week to learn about new features and updates for IBM watsonx.ai and IBM watsonx.governance.">
  <meta name="content.type" content="topic">
  <meta name="tags" content="{{ services }}">
  <meta name="account.plan" content="{{ account-plan }}">
  <meta name="completion.time" content="{{ completion-time }}">
  <meta name="version" content="{{ version }}">
  <meta name="deployment.url" content="{{ deployment-url }}">
  <meta name="industry" content="{{ industry }}">
  <meta name="compliance" content="{{ compliance }}">
  <meta name="use.case" content="{{ use-case }}">
  <meta name="source.format" content="markdown">




  <!-- Licensed Materials - Property of IBM -->
  <!-- US Government Users Restricted Rights -->
  <!-- Use, duplication or disclosure restricted by -->
  <!-- GSA ADP Schedule Contract with IBM Corp. -->

  <title>What's new</title>
<link rel="canonical" href="https://www.ibm.com/docs/en/watsonx-as-a-service?topic=overview-whats-new"><meta name="viewport" content="width=device-width,initial-scale=1"></head>

<body>
  <main role="main">
    <article aria-labelledby="whats-new" role="article">
      <style>
        .midd::after {
          content: "\A\00A0\00A0";
          white-space: pre
        }
      </style>
      <section id="section-whats-new">
        <h1 id="whats-new">What's new</h1>
        <p>Check back each week to learn about new features and updates for IBM watsonx.ai and IBM watsonx.governance.</p>
        <div class="note tip"><span class="tiptitle">Tip:</span> Occasionally, you must take a specific action after an update. To see all required actions, search this page for “Action required”.</div>
        <section id="section-week-2024-04-19">
          <h2 id="week-2024-04-19">Week ending 19 April 2024</h2>
          <section id="section-new-meta-llama-3-foundation-models-are-now-available">
            <h3 id="new-meta-llama-3-foundation-models-are-now-available">New Meta Llama 3 foundation models are now available</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>The following Llama 3 foundation models provided by Meta are available for inferencing from watsonx.ai:</p>
            <ul>
              <li>llama-3-8b-instruct</li>
              <li>llama-3-70b-instruct</li>
            </ul>
            <p>The new Llama 3 foundation models are instruction fine-tuned language models that can support various use cases.</p>
            <p>This latest release of Llama is trained with more tokens and applies new post-training procedures. The result is foundation models with better language comprehension, reasoning, code generation, and instruction-following capabilities.</p>
            <p>For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
          <section id="section-introducing-ibm-embedding-support-for-enhanced-text-matching-and-retrieval">
            <h3 id="introducing-ibm-embedding-support-for-enhanced-text-matching-and-retrieval">Introducing IBM embedding support for enhanced text matching and retrieval</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>You can now use the IBM embeddings API and IBM embedding models for transforming input text into vectors to more accurately compare and retrieve similar text.</p>
            <p>The following IBM Slate embedding models are available:</p>
            <ul>
              <li>slate.125m.english.rtrvr</li>
              <li>slate.30m.english.rtrvr</li>
            </ul>
            <p>For more information, see <a href="../analyze-data/fm-embed-overview.html">Text embedding generation</a>.</p>
            <p>For pricing details, see <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a>.</p>
          </section>
          <section id="section-ibm-watsonxgovernance-is-included-when-you-sign-up-for-ibm-watsonxai">
            <h3 id="ibm-watsonxgovernance-is-included-when-you-sign-up-for-ibm-watsonxai">IBM watsonx.governance is included when you sign up for IBM watsonx.ai</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>If you sign up for watsonx.ai in the Dallas region, watsonx.governance is now included automatically. See <a href="signup-wx.html">Signing up for IBM watsonx as a Service</a>.</p>
          </section>
          <section id="section-evaluate-machine-learning-deployments-in-spaces">
            <h3 id="evaluate-machine-learning-deployments-in-spaces">Evaluate machine learning deployments in spaces</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>Configure watsonx.governance evaluations in your deployment spaces to gain insights about your machine learning model performance. For example, evaluate a deployment for bias or monitor a deployment for drift. When you configure evaluations,
              you can analyze evaluation results and model transaction records directly in your spaces.</p>
            <p>For more information, see <a href="../analyze-data/ml-deploy-manage-monitor.html">Evaluating deployments in spaces</a>.</p>
          </section>
          <section id="section-a-korean-language-foundation-model-is-available-in-the-tokyo-region">
            <h3 id="a-korean-language-foundation-model-is-available-in-the-tokyo-region">A Korean-language foundation model is available in the Tokyo region</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>The llama2-13b-dpo-v7 foundation model provided by Minds &amp; Company and based on the Llama 2 foundation model from Meta is available in the Tokyo region.</p>
            <p>The llama2-13b-dpo-v7 foundation model specializes in conversational tasks in Korean and English. You can also use the llama2-13b-dpo-v7 foundation model for general purpose tasks in the Korean language.</p>
            <p>For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
          <section id="section-a-mixtral-8x7b-instruct-v01-foundation-model-is-available-for-inferencing">
            <h3 id="a-mixtral-8x7b-instruct-v01-foundation-model-is-available-for-inferencing">A mixtral-8x7b-instruct-v01 foundation model is available for inferencing</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>The mixtral-8x7b-instruct-v01 foundation model from Mistral AI is available for inferencing from watsonx.ai. The mixtral-8x7b-instruct-v01 foundation model is a pretrained generative model that uses a sparse mixture-of-experts network to generate
              text more efficiently.</p>
            <p>You can use the mixtral-8x7b-instruct-v01 model for general-purpose tasks, including classification, summarization, code generation, language translation, and more. For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
            <p>The mixtral-8x7b-instruct-v01-q foundation model is deprecated and will be withdrawn on 23 May 2024. Revise any prompts that use this foundation model.</p>
            <ul>
              <li>Deprecation date: 19 April 2024</li>
              <li>Withdrawal date: 23 May 2024</li>
              <li>Alternative model: mixtral-8x7b-instruct-v01</li>
            </ul>
            <p>Inference requests that are submitted to the mixtral-8x7b-instruct-v01-q model by using the API continue to generate output, but include a warning message about the upcoming model withdrawal. Starting on 23 May 2024, API requests for inferencing
              the models will not generate output.</p>
            <p>For more information about deprecation and withdrawal, see <a href="../analyze-data/fm-model-lifecycle.html">Foundation model lifecycle</a>.</p>
          </section>
          <section id="section-a-modification-to-the-granite-20b-multilingual-foundation-model-is-introduced">
            <h3 id="a-modification-to-the-granite-20b-multilingual-foundation-model-is-introduced">A modification to the granite-20b-multilingual foundation model is introduced</h3>
            <p class="idate-2024-04-18">18 Apr 2024</p>
            <p>The latest version of the granite-20b-multilingual is 1.1.0. The modification includes improvements that were gained by applying a novel AI alignment technique to the version 1.0 model. AI alignment involves using fine-tuning and reinforcement
              learning techniques to guide the model to return outputs that are as helpful, truthful, and transparent as possible.</p>
            <p>For more information about this foundation model, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-04-12">
          <h2 id="week-2024-04-12">Week ending 12 April 2024</h2>
          <section id="section-prompt-tune-the-granite-13b-instruct-v2-foundation-model">
            <h3 id="prompt-tune-the-granite-13b-instruct-v2-foundation-model">Prompt-tune the granite-13b-instruct-v2 foundation model</h3>
            <p class="idate-2024-04-11">11 Apr 2024</p>
            <p>The Tuning Studio now supports tuning the granite-13b-instruct-v2 foundation model in addition to the flan-t5-xl-3b and llama-2-13b-chat foundation models. For more information, see <a href="../analyze-data/fm-tuning-tune.html">Tuning a foundation model</a>.</p>
            <p>The experiment configuration settings for tuning the granite-13b-instruct-v2 foundation model change to apply the best default values depending on your task. The tuning evaluation guidelines help you to analyze the experiment results and adjust
              experiment configuration settings based on your findings. For more information, see <a href="../analyze-data/fm-tuning-methodology.html">Evaluating the results of a tuning experiment</a>.</p>
          </section>
          <section id="section-an-arabic-language-foundation-model-is-available-in-the-frankfurt-region">
            <h3 id="an-arabic-language-foundation-model-is-available-in-the-frankfurt-region">An Arabic-language foundation model is available in the Frankfurt region</h3>
            <p class="idate-2024-04-11">11 Apr 2024</p>
            <p>The jais-13b-chat foundation model provided by Inception, Mohamed bin Zayed University of Artificial Intelligence, and Cerebras Systems is available in the Frankfurt region.</p>
            <p>The jais-13b-chat foundation model specializes in conversational tasks in Arabic and English. You can also use the jais-13b-chat foundation model for general purpose tasks in the Arabic language, including language translation between Arabic
              and English.</p>
            <p>For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
          <section id="section-view-the-full-text-of-a-prompt-in-prompt-lab">
            <h3 id="view-the-full-text-of-a-prompt-in-prompt-lab">View the full text of a prompt in Prompt Lab</h3>
            <p class="idate-2024-04-11">11 Apr 2024</p>
            <p>Now you can review the full prompt text that will be submitted to the foundation model, which is useful when your prompt includes prompt variables or when you're working in structured mode or chat mode.</p>
            <p>For more information, see <a href="../analyze-data/fm-prompt-lab.html">Prompt Lab</a>.</p>
          </section>
          <section id="section-the-deprecated-granite-version-1-models-are-withdrawn">
            <h3 id="the-deprecated-granite-version-1-models-are-withdrawn">The deprecated Granite version 1 models are withdrawn</h3>
            <p class="idate-2024-04-11">11 Apr 2024</p>
            <p>The following foundation models are now withdrawn:</p>
            <ul>
              <li>granite-13b-chat-v1</li>
              <li>granite-13b-instruct-v1</li>
            </ul>
            <p>Revise any prompts that use these foundation models to use the IBM Granite v2 foundation models. For more information about foundation model deprecation and withdrawal, see <a href="../analyze-data/fm-model-lifecycle.html">Foundation model lifecycle</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-04-05">
          <h2 id="week-2024-04-05">Week ending 5 April 2024</h2>
          <section id="section-use-pivot-tables-to-display-data-aggregated-in-decision-optimization-experiments">
            <h3 id="use-pivot-tables-to-display-data-aggregated-in-decision-optimization-experiments">Use pivot tables to display data aggregated in Decision Optimization experiments</h3>
            <p class="idate-2024-04-05">5 Apr 2024</p>
            <p>You can now use pivot tables to display both input and output data aggregated in the <strong>Visualization</strong> view in Decision Optimization experiments. For more information, see <a href="../../DO/do_visualization/visuwidgets.html">Visualization widgets in Decision Optimization experiments</a>.</p>
          </section>
          <section id="section-new-watsonxai-tutorial-and-video">
            <h3 id="new-watsonxai-tutorial-and-video">New watsonx.ai tutorial and video</h3>
            <p class="idate-2024-04-04">04 Apr 2024</p>
            <p>Try the new tutorial to see how to use watsonx.ai in an end-to-end use case from data preparation through prompt engineering.</p>
            <table>
              <thead>
                <tr>
                  <th>Tutorial</th>
                  <th>Description</th>
                  <th>Expertise for tutorial</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="get-started-watsonx-ai-e2e.html">Try the watsonx.ai end-to-end use case</a></td>
                  <td>Follow a use case from data preparation through prompt engineering.</td>
                  <td>Use various tools, such as notebooks and Prompt Lab.<br><button class="bx--tag bx--tag--blue"><span class="bx--tag__label">Intermediate</span></button> <button class="bx--tag bx--tag--purple"><span class="bx--tag__label">All code</span></button></td>
                </tr>
              </tbody>
            </table>
          </section>
        </section>
        <section id="section-week-2024-03-15">
          <h2 id="week-2024-03-15">Week ending 15 March 2024</h2>
          <section id="section-the-watsonxai-api-is-available">
            <h3 id="the-watsonxai-api-is-available">The watsonx.ai API is available</h3>
            <p class="idate-2024-03-14">14 Mar 2024</p>
            <p>The watsonx.ai API is generally available. Use the watsonx.ai API to work with foundation models programmatically. For more information, see the <a href="https://cloud.ibm.com/apidocs/watsonx-ai" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">API reference</a>.</p>
            <p>The API version is <code>2024-03-14</code>.</p>
            <p>You can continue to use the Python library that is available for working with foundation models from a notebook. For more information, see <a href="../analyze-data/fm-python-lib.html">Python library</a>.</p>
          </section>
          <section id="section-new-foundation-models-are-available-in-dallas-frankfurt-and-tokyo">
            <h3 id="new-foundation-models-are-available-in-dallas-frankfurt-and-tokyo">New foundation models are available in Dallas, Frankfurt, and Tokyo</h3>
            <p class="idate-2024-03-14">14 Mar 2024</p>
            <p>The following foundation models are now available for inferencing from watsonx.ai:</p>
            <ul>
              <li>
                <p>granite-20b-multilingual: A foundation model from the IBM Granite family that you can use for various generative tasks in English, German, Spanish, French, and Portuguese.</p>
              </li>
              <li>
                <p>codellama-34b-instruct-hf: A programmatic code generation model from Code Llama that is based on Llama 2 from Meta. You can use codellama-34b-instruct-hf to create prompts for generating code based on natural language inputs, and for completing
                  and debugging code.</p>
              </li>
            </ul>
            <p>For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-03-08">
          <h2 id="week-2024-03-08">Week ending 8 March 2024</h2>
          <section id="section-the-tuning-studio-is-available-in-frankfurt">
            <h3 id="the-tuning-studio-is-available-in-frankfurt">The Tuning Studio is available in Frankfurt</h3>
            <p class="idate-2024-03-07">7 Mar 2024</p>
            <p>The Tuning Studio is now available to users of paid plans in the Frankfurt region. Tuning Studio helps you to guide a foundation model to return useful output. You can tune both the flan-t5-xl-3b and llama-2-70b-chat foundation models when
              you use the Tuning Studio in Frankfurt.</p>
            <p>For more information, see <a href="../analyze-data/fm-tuning-studio.html">Tuning Studio</a>.</p>
          </section>
          <section id="section-prompt-tune-the-llama-2-13b-chat-foundation-model-in-the-tokyo-region">
            <h3 id="prompt-tune-the-llama-2-13b-chat-foundation-model-in-the-tokyo-region">Prompt-tune the llama-2-13b-chat foundation model in the Tokyo region</h3>
            <p class="idate-2024-03-07">7 Mar 2024</p>
            <p>The Tuning Studio now supports tuning the llama-2-13b-chat foundation model in the Tokyo region. First, engineer prompts for the larger llama-2-70b-chat model in the Prompt Lab to find effective prompt inputs for your use case. Then tune the
              smaller version of the Llama 2 model to generate comparable, if not better outputs with zero-shot prompts.</p>
            <p>For more information, see <a href="../analyze-data/fm-tuning-studio.html">Tuning Studio</a>.</p>
          </section>
          <section id="section-lower-price-for-mixtral8x7b-model">
            <h3 id="lower-price-for-mixtral8x7b-model">Lower price for Mixtral8x7b model</h3>
            <p class="idate-2024-03-05">5 Mar 2024</p>
            <p>The foundation model mixtral-8x7b-instruct-v01-q is reclassified from Class 2: $0.0018/Resource Unit to Class 1: $0.0006/Resource Unit, making it more cost effective to run inferencing tasks against this model. The reclassification applies
              to all regions where mixtral-8x7b-instruct-v01-q is available.</p>
            <p>For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
            <p>For pricing details, see <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a>.</p>
          </section>
          <section id="section-ai-risk-atlas-is-updated-and-enhanced">
            <h3 id="ai-risk-atlas-is-updated-and-enhanced">AI risk atlas is updated and enhanced</h3>
            <p class="idate-2024-03-05">5 Mar 2024</p>
            <p>You can now find the following new and enhanced content in the AI risk atlas:</p>
            <ul>
              <li>A new category of non-technical risks that spans governance, legal compliance, and societal impact risks</li>
              <li>New examples for risks</li>
              <li>Clearer definitions of risks</li>
            </ul>
            <p>See <a href="../ai-risk-atlas/ai-risk-atlas.html">AI risk atlas</a>.</p>
          </section>
          <section id="section-new-use-cases-for-watsonx">
            <h3 id="new-use-cases-for-watsonx">New use cases for watsonx</h3>
            <p class="idate-2024-03-05">5 Mar 2024</p>
            <p>The watsonx uses cases are available to help you see how you can use our products, services, and tools:</p>
            <ul>
              <li>watsonx.ai use case: This use case covers how you can transform your business processes with AI-driven solutions by integrating machine learning and generative AI into your operational framework.</li>
              <li>watsonx.governance use case: This use case covers how you can erive responsible, transparent, and explainable AI workflows with an integrated system for tracking, monitoring, and retraining AI models.</li>
            </ul>
            <p>See <a href="use-case-ai-overview.html">watsonx use cases</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-03-01">
          <h2 id="week-2024-03-01">Week ending 1 March 2024</h2>
          <section id="section-chat-mode-is-available-in-prompt-lab">
            <h3 id="chat-mode-is-available-in-prompt-lab">Chat mode is available in Prompt Lab</h3>
            <p class="idate-2024-02-29">29 Feb 2024</p>
            <p>Chat mode in Prompt Lab is a simple chat interface that makes it easier to experiment with foundation models. Chat mode augments the already available structured and freeform modes that are useful when building few- or many-shot prompts for
              tasks such as extraction, summarization, and classification. Use Chat mode to simulate question-answering or conversational interactions for chatbot and virtual assistant use cases.</p>
            <p>For more information, see <a href="../analyze-data/fm-prompt-lab.html#chat-mode">Prompt Lab</a>.</p>
          </section>
          <section id="section-a-japanese-language-granite-model-is-available-in-the-tokyo-region">
            <h3 id="a-japanese-language-granite-model-is-available-in-the-tokyo-region">A Japanese-language Granite model is available in the Tokyo region</h3>
            <p class="idate-2024-02-29">29 Feb 2024</p>
            <p>The granite-8b-japanese foundation model provided by IBM is available from watsonx.ai in the Tokyo region. The granite-8b-japanese foundation model is based on the IBM Granite Instruct model and is trained to understand and generate Japanese
              text.</p>
            <p>You can use the granite-8b-japanese foundation model for general purpose tasks in the Japanese language, such as classification, extraction, question-answering, and for language translation between Japanese and English.</p>
            <p>For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-02-23">
          <h2 id="week-2024-02-23">Week ending 23 February 2024</h2>
          <section id="section-lower-price-for-granite-13b-models">
            <h3 id="lower-price-for-granite-13b-models">Lower price for Granite-13b models</h3>
            <p class="idate-2024-02-21">21 Feb 2024</p>
            <p>Granite-13b models are reclassified from Class 2: $0.0018/Resource Unit to Class 1: $0.0006/Resource Unit, making it more cost effective to run inferencing tasks against these models. The reclassification applies to the following models in
              all regions where they are available:</p>
            <ul>
              <li>granite-13b-chat-v2</li>
              <li>granite-13b-chat-v1</li>
              <li>granite-13b-instruct-v2</li>
              <li>granite-13b-instruct-v1</li>
            </ul>
            <p>For more information on these models, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
            <p>For pricing details, see <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-02-16">
          <h2 id="week-2024-02-16">Week ending 16 February 2024</h2>
          <section id="section-new-shortcut-to-start-working-on-common-tasks">
            <h3 id="new-shortcut-to-start-working-on-common-tasks">New shortcut to start working on common tasks</h3>
            <p class="idate-2024-02-15">15 Feb 2024</p>
            <p>You can now start a common task in your project by clicking on a tile in the <strong>Start working</strong> section in the <strong>Overview</strong> tab. Use these shortcuts to start adding collaborators and data, and to experiment with and
              build models. Click <strong>View all</strong> to jump to a selection of tools.</p>
          </section>
          <section id="section-new-mixtral-8x7b-instruct-v01-q-foundation-model-for-general-purpose-tasks">
            <h3 id="new-mixtral-8x7b-instruct-v01-q-foundation-model-for-general-purpose-tasks">New mixtral-8x7b-instruct-v01-q foundation model for general-purpose tasks</h3>
            <p class="idate-2024-02-15">15 Feb 2024</p>
            <p>The mixtral-8x7b-instruct-v01-q foundation model provided by Mistral AI and quantized by IBM is available from watsonx.ai. The mixtral-8x7b-instruct-v01-q foundation model is a quantized version of the Mixtral 8x7B Instruct foundation model
              from Mistral AI.</p>
            <p>You can use this new model for general-purpose tasks, including classification, summarization, code generation, language translation, and more. For more information, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
            <p>The following models are deprecated and will be withdrawn soon. Revise any prompts that use these foundation models to use another foundation model, such as mixtral-8x7b-instruct-v01-q.</p>
            <table>
              <caption caption-side="top">Deprecated foundation models</caption>
              <thead>
                <tr>
                  <th>Deprecated model</th>
                  <th>Deprecation date</th>
                  <th>Withdrawal date</th>
                  <th>Alternative model</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>gpt-neox-20b</td>
                  <td>15 February 2024</td>
                  <td>21 March 2024</td>
                  <td>mixtral-8x7b-instruct-v01-q</td>
                </tr>
                <tr>
                  <td>mpt-7b-instruct2</td>
                  <td>15 February 2024</td>
                  <td>21 March 2024</td>
                  <td>mixtral-8x7b-instruct-v01-q</td>
                </tr>
                <tr>
                  <td>starcoder-15.5b</td>
                  <td>15 February 2024</td>
                  <td>11 April 2024</td>
                  <td>mixtral-8x7b-instruct-v01-q</td>
                </tr>
              </tbody>
            </table>
            <p>Inference requests that are submitted to these models by using the API continue to generate output, but include a warning message about the upcoming model withdrawal. When the withdrawal date is reached, API requests for inferencing the models
              will not generate output.</p>
            <p>For more information about deprecation and withdrawal, see <a href="../analyze-data/fm-model-lifecycle.html">Foundation model lifecycle</a>.</p>
          </section>
          <section id="section-a-modification-to-the-granite-13b-chat-v2-foundation-model-is-available">
            <h3 id="a-modification-to-the-granite-13b-chat-v2-foundation-model-is-available">A modification to the granite-13b-chat-v2 foundation model is available</h3>
            <p class="idate-2024-02-15">15 Feb 2024</p>
            <p>The latest version of the granite-13b-chat-v2 is 2.1.0. The modification includes improvements that were gained by applying a novel AI alignment technique to the version 2.0.0 model. AI alignment involves using fine-tuning and reinforcement
              learning techniques to guide the model to return outputs that are as helpful, truthful, and transparent as possible. For more information, see the <a href="https://research.ibm.com/blog/what-is-alignment-ai" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">What is AI alignment?</a> blog post from IBM Research.</p>
          </section>
          <section id="section-new-watsonx-tutorial-and-video">
            <h3 id="new-watsonx-tutorial-and-video">New watsonx tutorial and video</h3>
            <p class="idate-2024-02-15">15 Feb 2024</p>
            <p>Try the new watsonx.governance tutorial to help you learn how to evaluate a machine learning model for fairness, accuracy, drift, and explainability with Watson OpenScale.</p>
            <table>
              <caption caption-side="top">New tutorials</caption>
              <thead>
                <tr>
                  <th>Tutorial</th>
                  <th>Description</th>
                  <th>Expertise for tutorial</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="get-started-openscale.html">Evaluate a machine learning model</a></td>
                  <td>Deploy a model, configure monitors for the deployed model, and evaluate the model.</td>
                  <td>Run a notebook to configure the models and use Watson OpenScale to evaluate.<br><button class="bx--tag bx--tag--blue"><span class="bx--tag__label">Intermediate</span></button> <button class="bx--tag bx--tag--blue"><span class="bx--tag__label">Low code</span></button></td>
                </tr>
              </tbody>
            </table>
            <br>
          </section>
        </section>
        <section id="section-week-2024-02-09">
          <h2 id="week-2024-02-09">Week ending 09 February 2024</h2>
          <section id="section-more-task-oriented-decision-optimization-documentation">
            <h3 id="more-task-oriented-decision-optimization-documentation">More task-oriented Decision Optimization documentation</h3>
            <p class="idate-2024-02-09">9 Feb 2024</p>
            <p>You can now more easily find the right information for creating and configuring Decision Optimization experiments. See <a href="../../DO/do_expts/doexptsintro.html">Decision Optimization experiments and its subsections</a>.</p>
          </section>
          <section id="section-ibm-cloud-data-engine-connection-is-deprecated">
            <h3 id="ibm-cloud-data-engine-connection-is-deprecated">IBM Cloud Data Engine connection is deprecated</h3>
            <p class="idate-2024-12-09">8 Feb 2022</p>
            <p>The IBM Cloud Data Engine connection is deprecated and will be discontinued in a future release. See <a href="https://cloud.ibm.com/docs/sql-query?topic=sql-query-deprecation" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Deprecation of Data Engine</a>              for important dates and details.</p>
          </section>
          <section id="section-new-spark-34-environment-for-running-data-refinery-flow-jobs">
            <h3 id="new-spark-34-environment-for-running-data-refinery-flow-jobs">New Spark 3.4 environment for running Data Refinery flow jobs</h3>
            <p class="idate-2024-02-09">9 Feb 2024</p>
            <p>When you select an environment for a Data Refinery flow job, you can now select <strong>Default Spark 3.4 &amp; R 4.2</strong>, which includes enhancements from Spark.</p>
            <p><img src="images/dr-spark-3.4.png" alt="Data Refinery Spark environments" width="500px"></p>
            <p>The <strong>Default Spark 3.3 &amp; R 4.2</strong> environment is deprecated and will be removed in a future update.</p>
            <p>Update your Data Refinery flow jobs to use the new <strong>Default Spark 3.4 &amp; R 4.2</strong> environment. For details, see <a href="../analyze-data/spark-dr-envs.html">Compute resource options for Data Refinery in projects</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-02-02">
          <h2 id="week-2024-02-02">Week ending 2 February 2024</h2>
          <section id="section-samples-collection-renamed-to-resource-hub">
            <h3 id="samples-collection-renamed-to-resource-hub">Samples collection renamed to Resource hub</h3>
            <p class="idate-2024-02-02">2 Feb 2024</p>
            <p>The Samples collection is renamed to Resource hub to better reflect the content. The Resource hub contains foundation models and sample projects, data sets, and notebooks. See <a href="https://dataplatform.cloud.ibm.com/samples?context=wx" target="_blank" class="external">Resource hub</a>.</p>
          </section>
          <section id="section-ibm-cloud-databases-for-datastax-connection-is-discontinued">
            <h3 id="ibm-cloud-databases-for-datastax-connection-is-discontinued">IBM Cloud Databases for DataStax connection is discontinued</h3>
            <p class="idate-2024-02-02">2 Feb 2024</p>
            <p>The IBM Cloud Databases for DataStax connection has been removed from IBM watsonx.ai.</p>
          </section>
          <section id="section-dremio-connection-requires-updates">
            <h3 id="dremio-connection-requires-updates">Dremio connection requires updates</h3>
            <p class="idate-2024-02-02">2 Feb 2024</p>
            <p>Previously the Dremio connection used a JDBC driver. Now the connection uses a driver based on Arrow Flight.</p>
            <p><button class="bx--tag bx--tag--red"><span class="bx--tag__label">Action required</span></button> <strong>Important</strong>: Update the connection properties. Different changes apply to a connection for a Dremio Software (on-prem) instance
              or a Dremio Cloud instance.</p>
            <section id="section-dremio-software-update-the-port-number">
              <h4 id="dremio-software-update-the-port-number">Dremio Software: Update the port number.</h4>
              <p>The new default port number that is used by Flight is <code>32010</code>. You can confirm the port number in the dremio.conf file. See <a href="https://docs.dremio.com/current/get-started/cluster-deployments/customizing-configuration/dremio-conf/" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Configuring via dremio.conf</a> for information.</p>
              <p>Additionally, Dremio no longer supports connections with IBM Cloud Satellite.</p>
            </section>
            <section id="section-dremio-cloud-update-the-authentication-method-and-hostname">
              <h4 id="dremio-cloud-update-the-authentication-method-and-hostname">Dremio Cloud: Update the authentication method and hostname.</h4>
              <ol>
                <li>Log into Dremio and generate a personal access token. For instructions see <a href="https://docs.dremio.com/cloud/security/authentication/personal-access-token/" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Personal Access Tokens</a>.</li>
                <li>In IBM watsonx in the <strong>Create connection: Dremio</strong> form, change the authentication type to <strong>Personal Access Token</strong> and add the token information. (The <strong>Username and password</strong> authentication can
                  no longer be used to connect to a Dremio Cloud instance.)</li>
                <li>Select <strong>Port is SSL-enabled</strong>.</li>
              </ol>
              <p>If you use the default hostname for a Dremio Cloud instance, you need to change it:</p>
              <ul>
                <li>Change <code>sql.dremio.cloud</code> to <code>data.dremio.cloud</code></li>
                <li>Change <code>sql.eu.dremio.cloud</code> to <code>data.eu.dremio.cloud</code></li>
              </ul>
            </section>
          </section>
          <section id="section-prompt-tune-the-llama-2-13b-chat-foundation-model">
            <h3 id="prompt-tune-the-llama-2-13b-chat-foundation-model">Prompt-tune the llama-2-13b-chat foundation model</h3>
            <p class="idate-2024-02-01">1 Feb 2024</p>
            <p>The Tuning Studio now supports tuning the llama-2-13b-chat foundation model. First, engineer prompts for the larger llama-2-70b-chat model in the Prompt Lab to find effective prompt inputs for your use case. Then tune the smaller version of
              the Llama 2 model to generate comparable, if not better outputs with zero-shot prompts. The llama-2-13b-model is available for prompt tuning in the Dallas region. For more information, see <a href="../analyze-data/fm-tuning-studio.html">Tuning Studio</a>.</p>
          </section>
        </section>
        <section id="section-week-2024-01-26">
          <h2 id="week-2024-01-26">Week ending 26 January 2024</h2>
          <section id="section-autoai-supports-ordered-data-for-all-experiments">
            <h3 id="autoai-supports-ordered-data-for-all-experiments">AutoAI supports ordered data for all experiments</h3>
            <p class="idate-2024-01-25">25 Jan 2024</p>
            <p>You can now specify ordered data for all AutoAI experiments rather than just time series experiments. Specify if your training data is ordered sequentially, according to a row index. When input data is sequential, model performance is evaluated
              on newest records instead of a random sampling, and holdout data uses the last <em>n</em> records of the set rather than <em>n</em> random records. Sequential data is required for time series experiments but optional for classification and
              regression experiments.</p>
          </section>
          <section id="section-qa-with-rag-accelerator">
            <h3 id="qa-with-rag-accelerator">Q&amp;A with RAG accelerator</h3>
            <p class="idate-2024-01-26">26 Jan 2024</p>
            <p>You can now implement a question and answer solution that uses retrieval augmented generation by importing a sample project. The sample project contains notebooks and other assets that convert documents from HTML or PDF to plain text, import
              document segments into an Elasticsearch vector index, deploy a Python function that queries the vector index, retrieve top N results, run LLM inference to generate an answer to the question, and check the answer for hallucinations.</p>
            <p>Try the <a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/75b22cbe-8a20-44a5-ac65-3a927e92cb0e?context=wx" target="_blank" class="external">Q&amp;A with RAG accelerator</a>.</p>
          </section>
          <section id="section-set-to-dark-theme">
            <h3 id="set-to-dark-theme">Set to dark theme</h3>
            <p class="idate-2024-01-25">25 Jan 2024</p>
            <p>You can now set your watsonx user interface to dark theme. Click your avatar and select <strong>Profile and settings</strong> to open your account profile. Then, set the Dark theme switch to on. Dark theme is not supported in RStudio and Jupyter
              notebooks. For information on managing your profile, see <a href="../admin/personal-settings.html">Managing your settings</a>.</p>
          </section>
          <section id="section-ibm-watsonxai-is-available-in-the-tokyo-region">
            <h3 id="ibm-watsonxai-is-available-in-the-tokyo-region">IBM watsonx.ai is available in the Tokyo region</h3>
            <p class="idate-2024-01-25">25 Jan 2024</p>
            <p>Watsonx.ai is now generally available in the Tokyo data center and can be selected as the preferred region when signing-up. The Prompt Lab and foundation model inferencing are supported in the Tokyo region for these models:</p>
            <ul>
              <li>elyza-japanese-llama-2-7b-instruct</li>
              <li>flan-t5-xl-3b</li>
              <li>flan-t5-xxl-11b</li>
              <li>flan-ul2-20b</li>
              <li>granite-13b-chat-v2</li>
              <li>granite-13b-instruct-v2</li>
              <li>llama-2-70b-chat</li>
              <li>llama-2-13b-chat</li>
            </ul>
            <p>Also available from the Tokyo region:</p>
            <ul>
              <li>Prompt tuning the flan-t5-xl-3b foundation model with the <a href="../analyze-data/fm-tuning-studio.html">Tuning Studio</a></li>
              <li>Generating tabular data with the Synthetic Data Generator to use for training models</li>
            </ul>
            <p>For more information on the supported models, see <a href="../analyze-data/fm-models.html">Supported foundation models available with watsonx.ai</a>.</p>
          </section>
          <section id="section-a-japanese-language-llama-2-model-is-available-in-the-tokyo-region">
            <h3 id="a-japanese-language-llama-2-model-is-available-in-the-tokyo-region">A Japanese-language Llama 2 model is available in the Tokyo region</h3>
            <p class="idate-2024-01-25">25 Jan 2024</p>
            <p>The elyza-japanese-llama-2-7b-instruct foundation model provided by ELYZA, Inc is available from watsonx.ai instances in the Tokyo data center. The elyza-japanese-llama-2-7b-instruct model is a version of the Llama 2 model from Meta that was
              trained to understand and generate Japanese text.</p>
            <p>You can use this new model for general purpose tasks. It works well for Japanese-language classification and extraction and for translation between Japanese and English.</p>
          </section>
        </section>
        <section id="section-week-2024-01-12">
          <h2 id="week-2024-01-12">Week ending 12 January 2024</h2>
          <section id="section-support-for-ibm-runtime-222-deprecated-in-watson-machine-learning">
            <h3 id="support-for-ibm-runtime-222-deprecated-in-watson-machine-learning">Support for IBM Runtime 22.2 deprecated in Watson Machine Learning</h3>
            <p class="idate-2024-01-11">11 Jan 2024</p>
            <p>IBM Runtime 22.2 is deprecated and will be removed on 11 April 2024. Beginning 7 March 2024, you cannot create notebooks or custom environments by using the 22.2 runtimes. Also, you cannot train new models with software specifications that
              are based on the 22.2 runtime.
              <button class="bx--tag bx--tag--red"><span class="bx--tag__label">Action required</span></button> Update your assets and deployments to use IBM Runtime 23.1 before 7 March 2024.</p>
            <ul>
              <li>To learn more about migrating an asset to a supported framework and software specification, see <a href="../analyze-data/ml-manage-outdated.html">Managing outdated software specifications or frameworks</a>.</li>
              <li>To learn more about the notebook environment, see <a href="../analyze-data/notebook-environments.html">Compute resource options for the notebook editor in projects</a>.</li>
              <li>To learn more about changing your environment, see <a href="../analyze-data/notebook-environments.html#change-env">Changing the environment of a notebook</a>.</li>
            </ul>
          </section>
          <section id="section-ibm-granite-v1-foundation-models-are-deprecated">
            <h3 id="ibm-granite-v1-foundation-models-are-deprecated">IBM Granite v1 foundation models are deprecated</h3>
            <p class="idate-2024-01-11">11 Jan 2024</p>
            <p>The IBM Granite 13 billion-parameter v1 foundation models are deprecated and will be withdrawn on 11 April 2024. If you are using version 1 of the models, switch to using version 2 of the models instead.</p>
            <table>
              <caption caption-side="top">Deprecated IBM foundation models</caption>
              <thead>
                <tr>
                  <th>Deprecated model</th>
                  <th>Deprecation date</th>
                  <th>Withdrawal date</th>
                  <th>Alternative model</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>granite-13b-chat-v1</td>
                  <td>11 January 2024</td>
                  <td>11 April 2024</td>
                  <td>granite-13b-chat-v2</td>
                </tr>
                <tr>
                  <td>granite-13b-instruct-v1</td>
                  <td>11 January 2024</td>
                  <td>11 April 2024</td>
                  <td>granite-13b-instruct-v2</td>
                </tr>
              </tbody>
            </table>
            <p>Inference requests that are submitted to the version 1 models by using the API continue to generate output, but include a warning message about the upcoming model withdrawal. Starting on 11 April 2024, API requests for inferencing the models
              will not generate output.</p>
            <p>For more information about IBM Granite foundation models, see <a href="../analyze-data/fm-models-ibm.html">Foundation models built by IBM</a>. For more information about deprecation and withdrawal, see <a href="../analyze-data/fm-model-lifecycle.html">Foundation model lifecycle</a>.</p>
          </section>
        </section>
        <section id="section-week-2023-12-15">
          <h2 id="week-2023-12-15">Week ending 15 December 2023</h2>
          <section id="section-create-user-api-keys-for-jobs-and-other-operations">
            <h3 id="create-user-api-keys-for-jobs-and-other-operations">Create user API keys for jobs and other operations</h3>
            <p class="idate-2023-12-15">15 Dec 2023</p>
            <p>Certain runtime operations in IBM watsonx, such as jobs and model training, require an API key as a credential for secure authorization. With user API keys, you can now generate and rotate an API key directly in IBM watsonx as needed to help
              ensure your operations run smoothly. The API keys are managed in IBM Cloud, but you can conveniently create and rotate them in IBM watsonx.</p>
            <p>The user API key is account-specific and is created from <strong>Profile and settings</strong> under your account profile.</p>
            <p>For more information, see <a href="../admin/admin-apikeys.html">Managing the user API key</a>.</p>
          </section>
          <section id="section-new-watsonx-tutorials-and-videos">
            <h3 id="new-watsonx-tutorials-and-videos">New watsonx tutorials and videos</h3>
            <p class="idate-2023-12-15">15 Dec 2023</p>
            <p>Try the new watsonx.governance and watsonx.ai tutorials to help you learn how to tune a foundation model, and evaluate and track a prompt template.</p>
            <table>
              <caption caption-side="top">New tutorials</caption>
              <thead>
                <tr>
                  <th>Tutorial</th>
                  <th>Description</th>
                  <th>Expertise for tutorial</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="get-started-tuning-studio.html">Tune a foundation model</a></td>
                  <td>Tune a foundation model to enhance model performance.</td>
                  <td>Use the Tuning Studio to tune a model without coding.<br><button class="bx--tag bx--tag--blue"><span class="bx--tag__label">Intermediate</span></button> <button class="bx--tag bx--tag--green"><span class="bx--tag__label">No code</span></button></td>
                </tr>
                <tr>
                  <td><a href="get-started-evaluate-prompt.html">Evaluate and track a prompt template</a></td>
                  <td>Evaluate a prompt template to measure the performance of foundation model and track the prompt template through its lifecycle.</td>
                  <td>Use the evaluation tool and an AI use case to track the prompt template.<br><button class="bx--tag bx--tag--green"><span class="bx--tag__label">Beginner</span></button> <button class="bx--tag bx--tag--green"><span class="bx--tag__label">No code</span></button></td>
                </tr>
              </tbody>
            </table>
            <br>
            <p><img src="images/lc-video.png" alt="Watch a video" title="Watch a video" height="20" style="vertical-align:text-bottom"> Find more watsonx.governance and watsonx.ai videos in the <a href="videos-wx.html">Video library</a>.</p>
          </section>
          <section id="section-new-login-session-expiration-and-sign-out-due-to-inactivity">
            <h3 id="new-login-session-expiration-and-sign-out-due-to-inactivity">New login session expiration and sign out due to inactivity</h3>
            <p class="idate-2023-12-15">15 Dec 2023</p>
            <p>You are now signed out of IBM Cloud due to session expiration. Your session can expire due to login session expiration (24 hours by default) or inactivity (2 hours by default). You can change the default durations in the Access (IAM) settings
              in IBM Cloud. For more information, see <a href="../admin/account-settings.html#set-expiration">Set the login session expiration</a>.</p>
          </section>
          <section id="section-ibm-cloud-databases-for-datastax-connector-is-deprecated">
            <h3 id="ibm-cloud-databases-for-datastax-connector-is-deprecated">IBM Cloud Databases for DataStax connector is deprecated</h3>
            <p class="idate-2023-12-15">15 Dec 2023</p>
            <p>The IBM Cloud Databases for DataStax connector is deprecated and will be discontinued in a future release.</p>
          </section>
        </section>
        <section id="section-week-2023-12-08">
          <h2 id="week-2023-12-08">Week ending 08 December 2023</h2>
          <section id="section-the-tuning-studio-is-available">
            <h3 id="the-tuning-studio-is-available">The Tuning Studio is available</h3>
            <p class="idate-2023-12-07">7 Dec 2023</p>
            <p>The Tuning Studio helps you to guide a foundation model to return useful output. With the Tuning Studio, you can prompt tune the flan-t5-xl-3b foundation model to improve its performance on natural language processing tasks such as classification,
              summarization, and generation. Prompt tuning helps smaller, more computationally-efficient foundation models achieve results comparable to larger models in the same model family. By tuning and deploying a tuned version of a smaller model,
              you can reduce long-term inference costs. The Tuning Studio is available to users of paid plans in the Dallas region.</p>
            <ul>
              <li>For more information, see <a href="../analyze-data/fm-tuning-studio.html">Tuning Studio</a>.</li>
              <li>To get started, see <a href="get-started-tuning-studio.html">Quick start: Tune a foundation model</a>.</li>
              <li>To run a sample notebook, go to <a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/bf57e8896f3e50c638b5a378780f7502" target="_blank" class="external">Tune a model to classify CFPB documents in watsonx</a>.</li>
            </ul>
          </section>
          <section id="section-new-client-properties-in-db2-connections-for-workload-management">
            <h3 id="new-client-properties-in-db2-connections-for-workload-management">New client properties in Db2 connections for workload management</h3>
            <p class="idate-2023-12-08">8 Dec 2023</p>
            <p>You can now specify properties in the following fields for monitoring purposes: <strong>Application name</strong>, <strong>Client accounting information</strong>, <strong>Client hostname</strong>, and <strong>Client user</strong>. These fields
              are optional and are available for the following connections:</p>
            <ul>
              <li><a href="../manage-data/conn-db2.html">IBM Db2</a></li>
              <li><a href="../manage-data/conn-db2zos.html">IBM Db2 for z/OS</a></li>
              <li><a href="../manage-data/conn-db2-wh.html">IBM Db2 Warehouse</a></li>
              <li><a href="../manage-data/conn-data-virtual.html">IBM Watson Query</a></li>
            </ul>
          </section>
        </section>
        <section id="section-week-2023-12-01">
          <h2 id="week-2023-12-01">Week ending 1 December 2023</h2>
          <section id="section-watsonxgovernance-is-available">
            <h3 id="watsonxgovernance-is-available">Watsonx.governance is available!</h3>
            <p class="idate-2023-12-01">1 Dec 2023</p>
            <p>Watsonx.governance extends the governance capabilities of Watson OpenScale to evaluate foundation model assets as well as machine learning assets. For example, evaluate foundation model prompt templates for dimensions such as accuracy or to
              detect the presence of hateful and abusive speech. You can also define AI use cases to address business problems, then track prompt templates or model data in factsheets to support compliance and governance goals. Watsonx.governance plans
              and features are available only in the Dallas region.</p>
            <ul>
              <li>To view plan details, see <a href="../model/wos-plan-options.html">watsonx.governance</a> plans.</li>
              <li>For details on governance features, see <a href="../analyze-data/xgov-overview.html">watsonx.governance overview</a>.</li>
              <li>To get started, see <a href="../model/wos-provision-launch.html">Provisioning and launching watsonx.governance</a>.</li>
            </ul>
          </section>
          <section id="section-explore-with-the-ai-risk-atlas">
            <h3 id="explore-with-the-ai-risk-atlas">Explore with the AI risk atlas</h3>
            <p class="idate-2023-12-01">1 Dec 2023</p>
            <p>You can now explore some of the risks of working with generative AI, foundation models, and machine learning models. Read about risks for privacy, fairness, explainability, value alignment, and other areas. See <a href="../ai-risk-atlas/ai-risk-atlas.html">AI risk atlas</a>.</p>
          </section>
          <section id="section-new-versions-of-the-ibm-granite-models-are-available">
            <h3 id="new-versions-of-the-ibm-granite-models-are-available">New versions of the IBM Granite models are available</h3>
            <p class="idate-2023-11-30">30 Nov 2023</p>
            <p>The latest versions of the Granite models include these changes:</p>
            <p><strong>granite-13b-chat-v2</strong>: Tuned to be better at question-answering, summarization, and generative tasks. With sufficient context, generates responses with the following improvements over the previous version:</p>
            <ul>
              <li>Generates longer, higher-quality responses with a professional tone</li>
              <li>Supports chain-of-thought responses</li>
              <li>Recognizes mentions of people and can detect tone and sentiment better</li>
              <li>Handles white spaces in input more gracefully</li>
            </ul>
            <p>Due to extensive changes, test and revise any prompts that were engineered for v1 before you switch to the latest version.</p>
            <p><strong>granite-13b-instruct-v2</strong>: Tuned specifically for classification, extraction, and summarization tasks. The latest version differs from the previous version in the following ways:</p>
            <ul>
              <li>Returns more coherent answers of varied lengths and with a diverse vocabulary</li>
              <li>Recognizes mentions of people and can summarize longer inputs</li>
              <li>Handles white spaces in input more gracefully</li>
            </ul>
            <p>Engineered prompts that work well with v1 are likely to work well with v2 also, but be sure to test before you switch models.</p>
            <p>The latest versions of the Granite models are categorized as Class 2 models.</p>
          </section>
          <section id="section-some-foundation-models-are-now-available-at-lower-cost">
            <h3 id="some-foundation-models-are-now-available-at-lower-cost">Some foundation models are now available at lower cost</h3>
            <p class="idate-2023-11-30">30 Nov 2023</p>
            <p>Some popular foundation models were recategorized into lower-cost billing classes.</p>
            <p>The following foundation models changed from Class 3 to Class 2:</p>
            <ul>
              <li>granite-13b-chat-v1</li>
              <li>granite-13b-instruct-v1</li>
              <li>llama-2-70b</li>
            </ul>
            <p>The following foundation model changed from Class 2 to Class 1:</p>
            <ul>
              <li>llama-2-13b</li>
            </ul>
            <p>For more information about the billing classes, see <a href="wml-plans.html">Watson Machine Learning plans</a>.</p>
          </section>
          <section id="section-a-new-sample-notebook-is-available-introduction-to-rag-with-discovery">
            <h3 id="a-new-sample-notebook-is-available-introduction-to-rag-with-discovery">A new sample notebook is available: Introduction to RAG with Discovery</h3>
            <p class="idate-2023-11-30">30 Nov 2023</p>
            <p>Use the <em>Introduction to RAG with Discovery</em> notebook to learn how to apply the retrieval-augmented generation pattern in IBM watsonx.ai with IBM Watson Discovery as the search component. For more information, see <a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/ba4a9e35-2091-49d3-9364-a1284afab7ec" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Introduction to RAG with Discovery</a>.</p>
          </section>
          <section id="section-understand-feature-differences-between-watsonx-as-a-service-and-software-deployments">
            <h3 id="understand-feature-differences-between-watsonx-as-a-service-and-software-deployments">Understand feature differences between watsonx as a service and software deployments</h3>
            <p class="idate-2023-11-30">30 Nov 2023</p>
            <p>You can now compare the features and implementation of IBM watsonx as a Service and watsonx on Cloud Pak for Data software, version 4.8. See <a href="feature-matrix.html">Feature differences between watsonx deployments</a>.</p>
          </section>
          <section id="section-change-to-how-stop-sequences-are-handled">
            <h3 id="change-to-how-stop-sequences-are-handled">Change to how stop sequences are handled</h3>
            <p class="idate-2023-11-30">30 Nov 2023</p>
            <p>When a stop sequence, such as a newline character, is specified in the Prompt Lab, the model output text ends after the first occurrence of the stop sequence. The model output stops even if the occurrence comes at the beginning of the output.
              Previously, the stop sequence was ignored if it was specified at the start of the model output.</p>
          </section>
        </section>
        <section id="section-week-2023-11-10">
          <h2 id="week-2023-11-10">Week ending 10 November 2023</h2>
          <section id="section-a-smaller-version-of-the-llama-2-chat-model-is-available">
            <h3 id="a-smaller-version-of-the-llama-2-chat-model-is-available">A smaller version of the Llama-2 Chat model is available</h3>
            <p class="idate-2023-11-09">9 Nov 2023</p>
            <p>You can now choose between using the 13b or 70b versions of the Llama-2 Chat model. Consider these factors when you make your choice:</p>
            <ul>
              <li>Cost</li>
              <li>Performance</li>
            </ul>
            <p>The 13b version is a Class 2 model, which means it is cheaper to use than the 70b version. To compare benchmarks and other factors, such as carbon emissions for each model size, see the <a href="https://dataplatform.cloud.ibm.com/wx/samples/models/meta-llama/llama-2-13b-chat?context=wx" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Model card</a>.</p>
          </section>
          <section id="section-use-prompt-variables-to-build-reusable-prompts">
            <h3 id="use-prompt-variables-to-build-reusable-prompts">Use prompt variables to build reusable prompts</h3>
            <p>Add flexibility to your prompts with <em>prompt variables</em>. Prompt variables function as placeholders in the static text of your prompt input that you can replace with text dynamically at inference time. You can save prompt variable names
              and default values in a prompt template asset to reuse yourself or share with collaborators in your project. For more information, see <a href="../analyze-data/fm-prompt-variables.html">Building reusable prompts</a>.</p>
          </section>
          <section id="section-announcing-support-for-python-310-and-r42-frameworks-and-software-specifications-on-runtime-231">
            <h3 id="announcing-support-for-python-310-and-r42-frameworks-and-software-specifications-on-runtime-231">Announcing support for Python 3.10 and R4.2 frameworks and software specifications on runtime 23.1</h3>
            <p class="idate-2023-11-09">9 Nov 2023</p>
            <p><button class="bx--tag bx--tag--red"><span class="bx--tag__label">Action required</span></button> You can now use IBM Runtime 23.1, which includes the latest data science frameworks based on Python 3.10 and R 4.2, to run Watson Studio Jupyter
              notebooks and R scripts, train models, and run Watson Machine Learning deployments. Update your assets and deployments to use IBM Runtime 23.1 frameworks and software specifications.</p>
            <ul>
              <li>For information on the IBM Runtime 23.1 release and the included environments for Python 3.10 and R 4.2, see <a href="../analyze-data/notebook-environments.html#change-env">Changing notebook environments</a>.</li>
              <li>For details on deployment frameworks, see <a href="../analyze-data/ml-manage-frame-and-specs.html">Managing frameworks and software specifications</a>.</li>
            </ul>
          </section>
          <section id="section-use-apache-spark-34-to-run-notebooks-and-scripts">
            <h3 id="use-apache-spark-34-to-run-notebooks-and-scripts">Use Apache Spark 3.4 to run notebooks and scripts</h3>
            <p>Spark 3.4 with Python 3.10 and R 4.2 is now supported as a runtime for notebooks and RStudio scripts in projects. For details on available notebook environments, see <a href="../analyze-data/notebook-environments.html">Compute resource options for the notebook editor in projects</a>              and <a href="../analyze-data/rstudio-envs.html">Compute resource options for RStudio in projects</a>.</p>
          </section>
        </section>
        <section id="section-week-2023-10-27">
          <h2 id="week-2023-10-27">Week ending 27 October 2023</h2>
          <section id="section-use-a-satellite-connector-to-connect-to-an-on-prem-database">
            <h3 id="use-a-satellite-connector-to-connect-to-an-on-prem-database">Use a Satellite Connector to connect to an on-prem database</h3>
            <p class="idate-2023-10-26">26 Oct 2023</p>
            <p>Use the new Satellite Connector to connect to a database that is not accessible via the internet (for example, behind a firewall). Satellite Connector uses a lightweight Docker-based communication that creates secure and auditable communications
              from your on-prem environment back to IBM Cloud. For instructions, see <a href="../manage-data/securingconn.html">Connecting to data behind a firewall</a>.</p>
          </section>
          <section id="section-secure-gateway-is-deprecated">
            <h3 id="secure-gateway-is-deprecated">Secure Gateway is deprecated</h3>
            <p class="idate-2023-10-26">26 Oct 2023</p>
            <p>IBM Cloud announced the deprecation of Secure Gateway. For information, see the <a href="https://cloud.ibm.com/docs/SecureGateway?topic=SecureGateway-dep-overview" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Overview and timeline</a>.</p>
            <p><button class="bx--tag bx--tag--red"><span class="bx--tag__label">Action required</span></button> If you currently have connections that are set up with Secure Gateway, plan to use an alternative communication method. In IBM watsonx, you can
              use the Satellite Connector as a replacement for Secure Gateway. See <a href="../manage-data/securingconn.html">Connecting to data behind a firewall</a>.</p>
          </section>
        </section>
        <section id="section-week-2023-10-20">
          <h2 id="week-2023-10-20">Week ending 20 October 2023</h2>
          <section id="section-maximum-token-sizes-increased">
            <h3 id="maximum-token-sizes-increased">Maximum token sizes increased</h3>
            <p class="idate-2023-10-16">16 Oct 2023</p>
            <p>Limits that were previously applied to the maximum number of tokens allowed in the output from foundation models are removed from paid plans. You can use larger maximum token values during prompt engineering from both the Prompt Lab and the
              Python library. The exact number of tokens allowed differs by model. For more information about token limits for paid and Lite plans, see <a href="../analyze-data/fm-models.html">Supported foundation models</a>.</p>
          </section>
        </section>
        <section id="section-week-2023-10-13">
          <h2 id="week-2023-10-13">Week ending 13 October 2023</h2>
          <section id="section-new-notebooks-in-samples">
            <h3 id="new-notebooks-in-samples">New notebooks in Samples</h3>
            <p class="idate-2023-10-12">12 Oct 2023</p>
            <p>Two new notebooks are available that use a vector database from Elasticsearch in the retrieval phase of the retrieval-augmented generation pattern. The notebooks demonstrate how to find matches based on the semantic similarity between the
              indexed documents and the query text that is submitted from a user.</p>
            <ul>
              <li><a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/ebeb9fc0-9844-4838-aff8-1fa1997d0c13?context=wx&amp;audience=wdp" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Sample notebook: Use watsonx, Elasticsearch, and LangChain to answer questions (RAG)</a></li>
              <li><a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/bdbc8ad4-9c1f-460f-99ee-5c3a1f374fa7?context=wx&amp;audience=wdp" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Sample notebook: Use watsonx, and Elasticsearch Python SDK to answer questions (RAG)</a></li>
            </ul>
          </section>
          <section id="section-intermediate-solutions-in-decision-optimization">
            <h3 id="intermediate-solutions-in-decision-optimization">Intermediate solutions in Decision Optimization</h3>
            <p class="idate-2023-10-12">12 Oct 2023</p>
            <p>You can now choose to see a sample of intermediate solutions while a Decision Optimization experiment is running. This can be useful for debugging or to see how the solver is progressing. For large models that take longer to solve, with intermediate
              solutions you can now quickly and easily identify any potential problems with the solve, without having to wait for the solve to complete.
              <img src="images/do-rundisplay.png" alt="Graphical display showing run statistics with intermediate solutions." style="max-width:90%;height:auto;width:auto"> You can configure the Intermediate solution delivery parameter in the Run configuration
              and select a frequency for these solutions. For more information, see <a href="../../DO/do_expts/intermedsolns.html">Intermediate solutions</a> and <a href="../../DO/do_expts/configrunparamscen.html">Run configuration parameters</a>.</p>
          </section>
          <section id="section-new-decision-optimization-saved-model-dialog">
            <h3 id="new-decision-optimization-saved-model-dialog">New Decision Optimization saved model dialog</h3>
            <p>When you save a model for deployment from the Decision Optimization user interface, you can now review the input and output schema, and more easily select the tables that you want to include. You can also add, modify or delete run configuration
              parameters, review the environment, and the model files used. All these items are displayed in the same <strong>Save as model for deployment</strong> dialog. For more information, see <a href="../../DO/WML_Deployment/DeployModelUI-WML.html">Deploying a Decision Optimization model by using the user interface</a>.</p>
          </section>
        </section>
        <section id="section-week-2023-10-06">
          <h2 id="week-2023-10-06">Week ending 6 October 2023</h2>
          <section id="section-additional-foundation-models-in-frankfurt">
            <h3 id="additional-foundation-models-in-frankfurt">Additional foundation models in Frankfurt</h3>
            <p class="idate-2023-10-05">5 Oct 2023</p>
            <p>All foundation models that are available in the Dallas data center are now also available in the Frankfurt data center. The watsonx.ai Prompt Lab and foundation model inferencing are now supported in the Frankfurt region for these models:</p>
            <ul>
              <li>granite-13b-chat-v1</li>
              <li>granite-13b-instruct-v1</li>
              <li>llama-2-70b-chat</li>
              <li>gpt-neox-20b</li>
              <li>mt0-xxl-13b</li>
              <li>starcoder-15.5b</li>
            </ul>
            <p>For more information on these models, see <a href="../analyze-data/fm-models.html">Supported foundation models available with watsonx.ai</a>.</p>
            <p>For pricing details, see <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a>.</p>
          </section>
          <section id="section-control-the-placement-of-a-new-column-in-the-concatenate-operation-data-refinery">
            <h3 id="control-the-placement-of-a-new-column-in-the-concatenate-operation-data-refinery">Control the placement of a new column in the Concatenate operation (Data Refinery)</h3>
            <p class="idate-2023-10-06">6 Oct 2023</p>
            <p>You now have two options to specify the position of the new column that results from the <strong>Concatenate</strong> operation: As the right-most column in the data set or next to the original column.</p>
            <p><img src="images/dr-concat-position.png" alt="Concatenate operation column position" title="Concatenate operation column position" height="500px"></p>
            <p>Previously, the new column was placed at the beginning of the data set.</p>
            <div class="note important"><span class="importanttitle">Important:</span>
              <md-block>
                <p><button class="bx--tag bx--tag--red"><span class="bx--tag__label">Action required</span></button> Edit the <strong>Concatenate</strong> operation in any of your existing Data Refinery flows to specify the new column position. Otherwise,
                  the flow might fail.</p>
                <p></p>
              </md-block>
            </div>
            <p></p>
            <p>For information about Data Refinery operations, see <a href="../refinery/gui_operations.html">GUI operations in Data Refinery</a>.</p>
          </section>
        </section>
        <section id="section-week-2023-09-29">
          <h2 id="week-2023-09-29">Week ending 29 September 2023</h2>
          <section id="section-ibm-granite-foundation-models-for-natural-language-generation">
            <h3 id="ibm-granite-foundation-models-for-natural-language-generation">IBM Granite foundation models for natural language generation</h3>
            <p class="idate-2023-09-28">28 Sept 2023</p>
            <p>The first two models from the Granite family of IBM foundation models are now available in the Dallas region:</p>
            <ul>
              <li><strong>granite-13b-chat-v1</strong>: General use model that is optimized for dialog use cases</li>
              <li><strong>granite-13b-instruct-v1</strong>: General use model that is optimized for question answering</li>
            </ul>
            <p>Both models are 13B-parameter decoder models that can efficiently predict and generate language in English. They, like all models in the Granite family, are designed for business. Granite models are pretrained on multiple terabytes of data
              from both general-language sources, such as the public internet, and industry-specific data sources from the academic, scientific, legal, and financial fields.</p>
            <p>Try them out today in the Prompt Lab or run a <a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/61c1e967-8d10-44bb-a846-cc1f27e9e69a" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">sample notebook</a>              that uses the granite-13b-instruct-v1 model for sentiment analysis.</p>
            <p>Read the <a href="https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models/" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Building AI for business: IBM’s Granite foundation models</a>              blog post to learn more.</p>
            <ul>
              <li>For more information on these models, see <a href="../analyze-data/fm-models.html">Supported foundation models available with watsonx.ai</a>.</li>
              <li>For a description of sample prompts, see <a href="../analyze-data/fm-prompt-samples.html">Sample foundation model prompts for common tasks</a>.</li>
              <li>For pricing details, see <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a>.</li>
            </ul>
          </section>
        </section>
        <section id="section-week-2023-09-22">
          <h2 id="week-2023-09-22">Week ending 22 September 2023</h2>
          <section id="section-decision-optimization-java-models">
            <h3 id="decision-optimization-java-models">Decision Optimization Java models</h3>
            <p class="idate-2023-09-20">20 Sept 2023</p>
            <p>Decision Optimization Java models can now be deployed in Watson Machine Learning. By using the Java worker API, you can create optimization models with OPL, CPLEX, and CP Optimizer Java APIs. You can now easily create your models locally,
              package them and deploy them on Watson Machine Learning by using the boilerplate that is provided in the public <a href="https://github.com/IBMDecisionOptimization/cplex-java-worker/blob/master/README.md">Java worker GitHub</a>. For more
              information, see <a href="../../DO/WML_Deployment/DeployJava.html">Deploying Java models for Decision Optimization</a>.</p>
          </section>
          <section id="section-new-notebooks-in-resource-hub">
            <h3 id="new-notebooks-in-resource-hub">New notebooks in Resource hub</h3>
            <p class="idate-2023-09-21">21 Sept 2023</p>
            <p>You can use the following new notebooks in Resource hub:</p>
            <ul>
              <li><a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/d3a5f957-a93b-46cd-82c1-c8d37d4f62c6" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Use watsonx and LangChain to answer questions using RAG</a></li>
              <li><a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/b5792ad4-555b-4b68-8b6f-ce368093fac6" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Use watsonx and BigCode <code>starcoder-15.5b</code> to generate code</a></li>
            </ul>
          </section>
        </section>
        <section id="section-week-2023-09-015">
          <h2 id="week-2023-09-015">Week ending 15 September 2023</h2>
          <section id="section-prompt-engineering-and-synthetic-data-quick-start-tutorials">
            <h3 id="prompt-engineering-and-synthetic-data-quick-start-tutorials">Prompt engineering and synthetic data quick start tutorials</h3>
            <p class="idate-2023-09-14">14 Sept 2023</p>
            <p>Try the new tutorials to help you learn how to:</p>
            <ul>
              <li>Prompt foundation models: There are usually multiple ways to prompt a foundation model for a successful result. In the Prompt Lab, you can experiment with prompting different foundation models, explore sample prompts, as well as save and
                share your best prompts. One way to improve the accuracy of generated output is to provide the needed facts as context in your prompt text using the retrieval-augmented generation pattern.</li>
              <li>Generate synthetic data: You can generate synthetic tabular data in watsonx.ai. The benefit to synthetic data is that you can procure the data on-demand, then customize to fit your use case, and produce it in large quantities.</li>
            </ul>
            <table>
              <caption caption-side="top">New tutorials</caption>
              <thead>
                <tr>
                  <th>Tutorial</th>
                  <th>Description</th>
                  <th>Expertise for tutorial</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="get-started-prompt-lab.html">Prompt a foundation model using Prompt Lab</a></td>
                  <td>Experiment with prompting different foundation models, explore sample prompts, and save and share your best prompts.</td>
                  <td>Prompt a model using Prompt Lab without coding.<br><button class="bx--tag bx--tag--green"><span class="bx--tag__label">Beginner</span></button> <button class="bx--tag bx--tag--green"><span class="bx--tag__label">No code</span></button></td>
                </tr>
                <tr>
                  <td><a href="get-started-fm-notebook.html">Prompt a foundation model with the retrieval-augmented generation pattern</a></td>
                  <td>Prompt a foundation model by leveraging information in a knowledge base.</td>
                  <td>Use the retrieval-augmented generation pattern in a Jupyter notebook that uses Python code.<br><button class="bx--tag bx--tag--blue"><span class="bx--tag__label">Intermediate</span></button> <button class="bx--tag bx--tag--purple"><span class="bx--tag__label">All code</span></button></td>
                </tr>
                <tr>
                  <td><a href="get-started-generate-data.html">Generate synthetic tabular data</a></td>
                  <td>Generate synthetic tabular data using a graphical flow editor.</td>
                  <td>Select operations to generate data.<br><button class="bx--tag bx--tag--green"><span class="bx--tag__label">Beginner</span></button> <button class="bx--tag bx--tag--green"><span class="bx--tag__label">No code</span></button></td>
                </tr>
              </tbody>
            </table>
          </section>
          <section id="section-watsonxai-community">
            <h3 id="watsonxai-community">Watsonx.ai Community</h3>
            <p class="idate-2023-09-14">14 Sept 2023</p>
            <p>You can now join the <a href="https://community.ibm.com/community/user/watsonx/communities/community-home?communitykey=81927b7e-9a92-4236-a0e0-018a27c4ad6e" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">watsonx.ai Community</a>              for AI architects and builders to learn, share ideas, and connect with others.</p>
          </section>
        </section>
        <section id="section-week-2023-09-08">
          <h2 id="week-2023-09-08">Week ending 8 September 2023</h2>
          <section id="section-generate-synthetic-tabular-data-with-synthetic-data-generator">
            <h3 id="generate-synthetic-tabular-data-with-synthetic-data-generator">Generate synthetic tabular data with Synthetic Data Generator</h3>
            <p class="idate-2023-09-07">7 Sept 2023</p>
            <p>Now available in the Dallas and Frankfurt regions, Synthetic Data Generator is a new graphical editor tool on watsonx.ai that you can use to generate tabular data to use for training models. Using visual flows and a statistical model, you
              can create synthetic data based on your existing data or a custom data schema. You can choose to mask your original data and export your synthetic data to a database or as a file.</p>
            <p>To get started, see <a href="../synthetic/synthetic_data_overview_sd.html">Synthetic data</a>.</p>
          </section>
          <section id="section-llama-2-foundation-model-for-natural-language-generation-and-chat">
            <h3 id="llama-2-foundation-model-for-natural-language-generation-and-chat">Llama-2 Foundation Model for natural language generation and chat</h3>
            <p class="idate-2023-09-07">7 Sept 2023</p>
            <p>The Llama-2 Foundation Model from Meta is now available in the Dallas region. Llama-2 Chat model is an auto-regressive language model that uses an optimized transformer architecture. The model is pretrained with publicly available online data,
              and then fine-tuned using reinforcement learning from human feedback. The model is intended for commercial and research use in English-language assistant-like chat scenarios.</p>
            <ul>
              <li>For more information on the Llama-2 model, see <a href="../analyze-data/fm-models.html">Supported foundation models available with watsonx.ai</a>.</li>
              <li>For a description of sample prompts, see <a href="../analyze-data/fm-prompt-samples.html">Sample foundation model prompts for common tasks</a>.</li>
              <li>For pricing details for Llama-2, see <a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a>.</li>
            </ul>
          </section>
          <section id="section-langchain-extension-for-the-foundation-models-python-library">
            <h3 id="langchain-extension-for-the-foundation-models-python-library">LangChain extension for the foundation models Python library</h3>
            <p class="idate-2023-09-07">7 Sept 2023</p>
            <p>You can now use the LangChain framework with foundation models in watsonx.ai with the new LangChain extension for the foundation models Python library.</p>
            <p>This sample notebook demonstrates how to use the new extension: <a href="https://dataplatform.cloud.ibm.com/exchange/public/entry/view/c3dbf23a-9a56-4c4b-8ce5-5707828fc981?context=wx" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Sample notebook</a></p>
          </section>
          <section id="section-introductory-sample-for-the-retrieval-augmented-generation-pattern">
            <h3 id="introductory-sample-for-the-retrieval-augmented-generation-pattern">Introductory sample for the retrieval-augmented generation pattern</h3>
            <p class="idate-2023-09-07">7 Sept 2023</p>
            <p>Retrieval-augmented generation is a simple, powerful technique for leveraging a knowledge base to get factually accurate output from foundation models.</p>
            <p>See: <a href="../analyze-data/fm-rag.html">Introduction to retrieval-augmented generation</a></p>
          </section>
        </section>
        <section id="section-week-2023-09-01">
          <h2 id="week-2023-09-01">Week ending 1 September 2023</h2>
          <section id="section-deprecation-of-comments-in-notebooks">
            <h3 id="deprecation-of-comments-in-notebooks">Deprecation of comments in notebooks</h3>
            <p class="idate-2023-08-31">31 Aug 2023</p>
            <p>As of today it is not possible to add comments to a notebook from the notebook action bar. Any existing comments were removed.</p>
            <p><img src="images/notebook-comments.png" alt="Comments icon in the notebook action bar" height="200px"></p>
          </section>
          <section id="section-starcoder-foundation-model-for-code-generation-and-code-translation">
            <h3 id="starcoder-foundation-model-for-code-generation-and-code-translation">StarCoder Foundation Model for code generation and code translation</h3>
            <p class="idate-2023-08-31">31 Aug 2023</p>
            <p>The StarCoder model from Hugging Face is now available in the Dallas region. Use StarCoder to create prompts for generating code or for transforming code from one programming language to another. One sample prompt demonstrates how to use StarCoder
              to generate Python code from a set of instruction. A second sample prompt demonstrates how to use StarCoder to transform code written in C++ to Python code.</p>
            <ul>
              <li>For more information on the StarCoder model, see <a href="../analyze-data/fm-models.html">Supported foundation models available with watsonx.ai</a>.</li>
              <li>For a description of the sample prompts, see <a href="../analyze-data/fm-prompt-samples.html">Sample foundation model prompts for common tasks</a>.</li>
            </ul>
          </section>
          <section id="section-ibm-watsonxai-is-available-in-the-frankfurt-region">
            <h3 id="ibm-watsonxai-is-available-in-the-frankfurt-region">IBM watsonx.ai is available in the Frankfurt region</h3>
            <p class="idate-2023-08-31">31 Aug 2023</p>
            <p>Watsonx.ai is now generally available in the Frankfurt data center and can be selected as the preferred region when signing-up. The Prompt Lab and foundation model inferencing are supported in the Frankfurt region for these models:</p>
            <ul>
              <li>
                <p>mpt-7b-instruct2</p>
              </li>
              <li>
                <p>flan-t5-xxl-11b</p>
              </li>
              <li>
                <p>flan-ul2-20b</p>
              </li>
              <li>
                <p>For more information on the supported models, see <a href="../analyze-data/fm-models.html">Supported foundation models available with watsonx.ai</a>.</p>
              </li>
            </ul>
          </section>
        </section>
        <section id="section-week-2023-08-25">
          <h2 id="week-2023-08-25">Week ending 25 August 2023</h2>
          <section id="section-additional-cache-enhancements-available-for-watson-pipelines">
            <h3 id="additional-cache-enhancements-available-for-watson-pipelines">Additional cache enhancements available for Watson Pipelines</h3>
            <p class="idate">21 August 2023</p>
            <p>More options are available for customizing your pipeline flow settings. You can now exercise greater control over when the cache is used for pipeline runs. For details, see <a href="../analyze-data/ml-orchestration-global-settings.html">Managing default settings</a>.</p>
          </section>
        </section>
        <section id="section-week-ending-18-august-2023">
          <h2 id="week-ending-18-august-2023">Week ending 18 August 2023</h2>
          <p id="week-2023-08-18"></p>
          <section id="section-plan-name-updates-for-watson-machine-learning-service">
            <h3 id="plan-name-updates-for-watson-machine-learning-service">Plan name updates for Watson Machine Learning service</h3>
            <p class="idate">18 August 2023</p>
            <p>Starting immediately, plan names are updated for the IBM Watson Machine Learning service, as follows:</p>
            <ul>
              <li>
                <p>The v2 Standard plan is now the <strong>Essentials</strong> plan. The plan is designed to give your organization the resources required to get started working with foundation models and machine learning assets.</p>
              </li>
              <li>
                <p>The v2 Professional plan is now the <strong>Standard</strong> plan. This plan provides resources designed to support most organizations through asset creation to productive use.</p>
              </li>
            </ul>
            <p>Changes to the plan names do not change your terms of service. That is, if you are registered to use the v2 Standard plan, it will now be named <strong>Essentials</strong>, but all of the plan details will remain the same. Similarly, if you
              are registered to use the v2 Professional plan, there are no changes other than the plan name change to <strong>Standard</strong>.</p>
            <p>For details on what is included with each plan, see <a href="wml-plans.html">Watson Machine Learning plans</a>. For pricing information, find your plan on the <a href="https://cloud.ibm.com/catalog/services/watson-machine-learning" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">Watson Machine Learning plan page</a> in the IBM Cloud catalog.</p>
          </section>
        </section>
        <section id="section-week-2023-08-11">
          <h2 id="week-2023-08-11">Week ending 11 August 2023</h2>
          <section id="section-deprecation-of-comments-in-notebooks-2">
            <h3 id="deprecation-of-comments-in-notebooks-2">Deprecation of comments in notebooks</h3>
            <p class="idate">7 August 2023</p>
            <p>On 31 August 2023, you will no longer be able to add comments to a notebook from the notebook action bar. Any existing comments that were added that way will be removed.</p>
            <p><img src="images/notebook-comments.png" alt="Comments icon in the notebook action bar" height="200px"></p>
          </section>
        </section>
        <section id="section-week-2023-08-04">
          <h2 id="week-2023-08-04">Week ending 4 August 2023</h2>
          <section id="section-increased-token-limit-for-lite-plan">
            <h3 id="increased-token-limit-for-lite-plan">Increased token limit for Lite plan</h3>
            <p class="idate">4 August 2023</p>
            <p>If you are using the Lite plan to test foundation models, the token limit for prompt input and output is now increased from 25,000 to 50,000 per account per month. This gives you more flexibility for exploring foundation models and experimenting
              with prompts.</p>
            <ul>
              <li>For details on watsonx.ai plans, see <a href="wml-plans.html">Watson Machine Learning plans</a>.</li>
              <li>For details on working with prompts, see <a href="../analyze-data/fm-prompt-lab.html">Engineer prompts with the Prompt Lab</a>.</li>
            </ul>
          </section>
          <section id="section-custom-text-analytics-template-spss-modeler">
            <h3 id="custom-text-analytics-template-spss-modeler">Custom text analytics template (SPSS Modeler)</h3>
            <p class="idate">4 August 2023</p>
            <p>For SPSS Modeler, you can now upload a custom text analytics template to a project. This provides you with more flexibility to capture and extract key concepts in a way that is unique to your context.</p>
          </section>
        </section>
        <section id="section-week-ending-28-july-2023">
          <h2 id="week-ending-28-july-2023">Week ending 28 July 2023</h2>
          <p id="week-2023-07-28"></p>
          <section id="section-foundation-models-python-library-available">
            <h3 id="foundation-models-python-library-available">Foundation models Python library available</h3>
            <p class="idate">27 July 2023</p>
            <p>You can now prompt foundation models in watsonx.ai programmatically using a Python library.</p>
            <p>See: <a href="../analyze-data/fm-python-lib.html">Foundation models Python library</a></p>
          </section>
        </section>
        <section id="section-week-2023-07-14">
          <h2 id="week-2023-07-14">Week ending 14 July 2023</h2>
          <section id="section-control-ai-guardrails">
            <h3 id="control-ai-guardrails">Control AI guardrails</h3>
            <p class="idate">14 July 2023</p>
            <p>You can now control whether AI guardrails are on or off in the Prompt Lab. AI guardrails remove potentially harmful text from both the input and output fields. Harmful text can include hate speech, abuse, and profanity. To prevent the removal
              of potentially harmful text, set the <strong>AI guardrails</strong> switch to off. See <a href="../analyze-data/fm-hallucinations.html#hap">Hate speech, abuse, and profanity</a>.</p>
            <p><img src="images/guardrails.png" alt="The Prompt Lab with AI guardrails set on" style="max-width:90%;height:auto;width:auto"></p>
          </section>
          <section id="section-microsoft-azure-sql-database-connection-supports-azure-active-directory-authentication-azure-ad">
            <h3 id="microsoft-azure-sql-database-connection-supports-azure-active-directory-authentication-azure-ad">Microsoft Azure SQL Database connection supports Azure Active Directory authentication (Azure AD)</h3>
            <p class="idate">14 July 2023</p>
            <p>You can now select Active Directory for the Microsoft Azure SQL Database connection. Active Directory authentication is an alternative to SQL Server authentication. With this enhancement, administrators can centrally manage user permissions
              to Azure. For more information, see <a href="../manage-data/conn-azure-sql.html">Microsoft Azure SQL Database connection</a>.</p>
          </section>
        </section>
        <section id="section-week-ending-7-july-2023">
          <h2 id="week-ending-7-july-2023">Week ending 7 July 2023</h2>
          <p id="week-2023-07-07"></p>
          <section id="section-welcome-to-ibm-watsonxai">
            <h3 id="welcome-to-ibm-watsonxai">Welcome to IBM watsonx.ai!</h3>
            <p class="idate">7 July 2023</p>
            <p>IBM watsonx.ai delivers all the tools that you need to work with machine learning and foundation models.</p>
            <p>Get started:</p>
            <ul>
              <li><a href="overview-wx.html">Learn about watsonx.ai</a></li>
              <li><a href="../analyze-data/fm-overview.html">Learn about foundation models</a></li>
              <li><a href="../analyze-data/fm-prompt-lab.html">Engineer prompts with the Prompt Lab</a></li>
              <li><a href="quickstart-tutorials.html">Take quick start tutorials</a></li>
              <li><a href="../analyze-data/watson-nlp.html">Watson Natural Language Processing</a></li>
            </ul>
          </section>
          <section id="section-try-generative-ai-search-and-answer-in-this-documentation">
            <h3 id="try-generative-ai-search-and-answer-in-this-documentation">Try generative AI search and answer in this documentation</h3>
            <p class="idate">7 July 2023</p>
            <p>You can see generative AI in action by trying the new generative AI search and answer option in the watsonx.ai documentation. The answers are generated by a large language model running in watsonx.ai and based on the documentation content.
              This feature is only available when you are viewing the documentation while logged in to watsonx.ai.</p>
            <p>Enter a question in the documentation search field and click the <strong>Try generative AI search and answer</strong> icon (<img src="images/bee.png" alt="Try generative AI search and answer icon" height="20" style="vertical-align:text-bottom">).
              The <strong>Generative AI search and answer</strong> pane opens and answers your question.</p>
            <p><img src="images/gen-ai-search.png" alt="Shows the generative AI search and answer pane" style="max-width:90%;height:auto;width:auto"></p>
          </section>
        </section>
      </section>
    </article>
  </main>

<script type="text/javascript"  src="/DEWsG3/JOI980/yQyM/iRupUf/mVarA/YDJa4kXtLhb7/LwkITClvAg/Wgkg/WmBVIDs"></script><link rel="stylesheet" type="text/css"  href="/_sec/cp_challenge/sec-4-4.css">
                                        <script  src="/_sec/cp_challenge/sec-cpt-4-4.js" async defer></script>
                                        <div id="sec-overlay" style="display:none;">
                                        <div id="sec-container">
                                        </div>
                                      </div></body></html>