<!DOCTYPE html><html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="DC.Publisher" content="IBM Corporation">
  <meta name="DC.rights" content="© Copyright IBM Corporation {{ copyright.years }}">
  <meta name="IBM.Country" content="ZZ">
  <meta name="DC.Date" content="{{ lastupdated }}">
  <meta name="keywords" content="{{ keywords }}">
  <meta name="subcollection" content="{{ subcollection }}">
  <meta name="description" content="To determine which models might work well for your project, find a model that supports the task you need to complete for your use case and that supports the language of the text you need to process. Also, consider model attributes, such as license, pretraining data, model size, and how the model was fine-tuned. After you have a short list of models that best fit your use case, you can test the models to see which ones consistently return the results you want.">
  <meta name="content.type" content="topic">
  <meta name="tags" content="{{ services }}">
  <meta name="account.plan" content="{{ account-plan }}">
  <meta name="completion.time" content="{{ completion-time }}">
  <meta name="version" content="{{ version }}">
  <meta name="deployment.url" content="{{ deployment-url }}">
  <meta name="industry" content="{{ industry }}">
  <meta name="compliance" content="{{ compliance }}">
  <meta name="use.case" content="{{ use-case }}">
  <meta name="source.format" content="markdown">




  <!-- Licensed Materials - Property of IBM -->
  <!-- US Government Users Restricted Rights -->
  <!-- Use, duplication or disclosure restricted by -->
  <!-- GSA ADP Schedule Contract with IBM Corp. -->

  <title>Choosing a foundation model in watsonx.ai</title>
<link rel="canonical" href="https://www.ibm.com/docs/en/watsonx-as-a-service?topic=models-choosing-model"><meta name="viewport" content="width=device-width,initial-scale=1"></head>

<body>
  <main role="main">
    <article aria-labelledby="choosing-a-foundation-model-in-watsonxai" role="article">
      <style>
        .midd::after {
          content: "\A\00A0\00A0";
          white-space: pre
        }
      </style>
      <section id="section-choosing-a-foundation-model-in-watsonxai">
        <h1 id="choosing-a-foundation-model-in-watsonxai">Choosing a foundation model in watsonx.ai</h1>
        <p>To determine which models might work well for your project, find a model that supports the task you need to complete for your use case and that supports the language of the text you need to process. Also, consider model attributes, such as license,
          pretraining data, model size, and how the model was fine-tuned. After you have a short list of models that best fit your use case, you can test the models to see which ones consistently return the results you want.</p>
        <section id="section-foundation-models-that-support-your-use-case">
          <h2 id="foundation-models-that-support-your-use-case">Foundation models that support your use case</h2>
          <p>To get started, find foundation models that can do the type of task that you want to complete.</p>
          <p>The following table shows the types of tasks that the foundation models in IBM watsonx.ai support. A checkmark (✓) indicates that the task named in the column header is supported by the foundation model. For some of the models, you can click
            <strong>See sample</strong> to see a sample prompt that can be used for the task. Alternatively, see <a href="fm-prompt-samples.html">Sample prompts</a> to review many prompt samples that are grouped by task type.</p>
          <table>
            <caption caption-side="top">Table 1. Foundation model task support</caption>
            <thead>
              <tr>
                <th>Model</th>
                <th>Classification</th>
                <th>Extraction</th>
                <th>Generation</th>
                <th>Question-answering</th>
                <th>Retrieval-augmented generation</th>
                <th>Summarization</th>
                <th>Coding</th>
                <th>Translation</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>granite-13b-chat-v2</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample7c">See sample</a></td>
                <td></td>
                <td>✓</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>granite-13b-instruct-v2</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample3c">See sample</a></td>
                <td>✓</td>
                <td></td>
                <td>✓</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>granite-7b-lab</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>granite-8b-japanese</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample4e">See sample</a></td>
                <td></td>
                <td>✓</td>
                <td></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample8c">See sample</a></td>
              </tr>
              <tr>
                <td>granite-20b-multilingual</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td>✓</td>
                <td></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample8d">See sample</a></td>
              </tr>
              <tr>
                <td>codellama-34b-instruct-hf</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample6a">See sample</a></td>
                <td></td>
              </tr>
              <tr>
                <td>elyza-japanese-llama-2-7b-instruct</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample1d">See sample</a></td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample8a">See sample</a></td>
              </tr>
              <tr>
                <td>flan-t5-xl-3b</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>flan-t5-xxl-11b</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample1a">See sample</a></td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample4a">See sample</a></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample5a">See sample</a></td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>flan-ul2-20b</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample1a">See sample</a></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample2a">See sample</a></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample4b">See sample</a></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample5a">See sample</a></td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>jais-13b-chat</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample7e">See sample</a></td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td>✓</td>
              </tr>
              <tr>
                <td>llama-3-8b-instruct</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
              </tr>
              <tr>
                <td>llama-3-70b-instruct</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
              </tr>
              <tr>
                <td>llama-2-13b-chat</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample7a">See sample</a></td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
              </tr>
              <tr>
                <td>llama-2-70b-chat</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample7a">See sample</a></td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
              </tr>
              <tr>
                <td>llama2-13b-dpo-v7</td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample5d">See sample</a></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample7f">See sample</a></td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
              </tr>
              <tr>
                <td>merlinite-7b</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td>✓</td>
                <td>✓</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>mixtral-8x7b-instruct-v01</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
              </tr>
              <tr>
                <td>mixtral-8x7b-instruct-v01-q</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample1b">See sample</a></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample3a">See sample</a></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample5b">See sample</a></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample6a">See sample</a></td>
                <td></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample8b">See sample</a></td>
              </tr>
              <tr>
                <td>mt0-xxl-13b</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample1a">See sample</a></td>
                <td></td>
                <td>✓</td>
                <td>✓<br><a href="fm-prompt-samples.html#sample4a">See sample</a></td>
                <td></td>
                <td>✓</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>starcoder-15.5b</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td>✓<br><a href="fm-prompt-samples.html#sample6a">See sample</a></td>
                <td></td>
              </tr>
            </tbody>
          </table>
        </section>
        <section id="section-foundation-models-that-support-your-language">
          <h2 id="foundation-models-that-support-your-language">Foundation models that support your language</h2>
          <p>Many foundation models work well in English only. But some model creators include multiple languages in the pretraining data sets to fine-tune their model on tasks in different languages, and to test their model's performance in multiple languages.
            If you plan to build a solution for a global audience or a solution that does translation tasks, look for models that were created with multilingual support in mind.</p>
          <p>The following table lists natural languages that are supported in addition to English by foundation models in watsonx.ai. For more information about the languages that are supported for multilingual foundation models, see the model card for
            the foundation model.</p>
          <table>
            <caption caption-side="top">Table 2. Foundation models that support natural languages other than English</caption>
            <thead>
              <tr>
                <th>Model</th>
                <th>Languages other than English</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>granite-8b-japanese</td>
                <td>Japanese</td>
              </tr>
              <tr>
                <td>granite-20b-multilingual</td>
                <td>German, Spanish, French, and Portuguese</td>
              </tr>
              <tr>
                <td>elyza-japanese-llama-2-7b-instruct</td>
                <td>Japanese</td>
              </tr>
              <tr>
                <td>flan-t5-xl-3b</td>
                <td>Multilingual (<a href="https://dataplatform.cloud.ibm.com/wx/samples/models/google/flan-t5-xl?context=wx" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">See model card</a>)</td>
              </tr>
              <tr>
                <td>flan-t5-xxl-11b</td>
                <td>French, German</td>
              </tr>
              <tr>
                <td>jais-13b-chat</td>
                <td>Arabic</td>
              </tr>
              <tr>
                <td>llama2-13b-dpo-v7</td>
                <td>Korean</td>
              </tr>
              <tr>
                <td>mixtral-8x7b-instruct-v01</td>
                <td>French, German, Italian, Spanish</td>
              </tr>
              <tr>
                <td>mixtral-8x7b-instruct-v01-q</td>
                <td>French, German, Italian, Spanish</td>
              </tr>
              <tr>
                <td>mt0-xxl-13b</td>
                <td>Multilingual (<a href="https://dataplatform.cloud.ibm.com/wx/samples/models/bigscience/mt0-xxl?context=wx" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">See model card</a>)</td>
              </tr>
            </tbody>
          </table>
        </section>
        <section id="section-more-considerations-for-choosing-a-model">
          <h2 id="more-considerations-for-choosing-a-model">More considerations for choosing a model</h2>
          <table>
            <caption caption-side="top">Table 3. Considerations for choosing a foundation model in IBM watsonx.ai</caption>
            <thead>
              <tr>
                <th>Model attribute</th>
                <th>Considerations</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Context length</td>
                <td>Sometimes called <em>context window length</em>, <em>context window</em>, or <em>maximum sequence length</em>, context length is the maximum allowed value for the number of tokens in the input prompt plus the number of tokens in the generated
                  output. When you generate output with models in watsonx.ai, the number of tokens in the generated output is limited by the Max tokens parameter. For some models, the token length of model output for Lite plans is limited by a dynamic,
                  model-specific, environment-driven upper limit.</td>
              </tr>
              <tr>
                <td>Cost</td>
                <td>The cost of using foundation models is measured in resource units. The price of a resource unit is based on the rate of the billing class for the foundation model.</td>
              </tr>
              <tr>
                <td>Fine-tuning</td>
                <td>After being pretrained, many foundation models are fine-tuned for specific tasks, such as classification, information extraction, summarization, responding to instructions, answering questions, or participating in a back-and-forth dialog
                  chat. A model that was fine-tuned on tasks similar to your planned use typically perform better with zero-shot prompts than models that were not fine-tuned in a way that fits your use case. One way to improve results for a fine-tuned
                  model is to structure your prompt in the same format as prompts in the data sets that were used to fine-tune that model.</td>
              </tr>
              <tr>
                <td>Instruction-tuned</td>
                <td><em>Instruction-tuned</em> means that the model was fine-tuned with prompts that include an instruction. When a model is instruction-tuned, it typically responds well to prompts that have an instruction even if those prompts don't have
                  examples.</td>
              </tr>
              <tr>
                <td>IP indemnity</td>
                <td>In addition to license terms, review the intellectual property indemnification policy for the model. Some foundation model providers require you to exempt them from liability for any IP infringement that might result from the use of their
                  AI models. For information about contractual protections related to IBM watsonx.ai, see the <a href="https://www.ibm.com/support/customer/csol/terms/?id=i126-7747" target="_blank" rel="noopener noreferrer" title="Opens a new window or tab">IBM watsonx.ai service description</a>.</td>
              </tr>
              <tr>
                <td>License</td>
                <td>In general, each foundation model comes with a different license that limits how the model can be used. Review model licenses to make sure that you can use a model for your planned solution.</td>
              </tr>
              <tr>
                <td>Model architecture</td>
                <td>The architecture of the model influences how the model behaves. A transformer-based model typically has one of the following architectures:<br>• <em>Encoder-only</em>: Understands input text at the sentence level by transforming input
                  sequences into representational vectors called embeddings. Common tasks for encoder-only models include classification and entity extraction.<br>• <em>Decoder-only</em>: Generates output text word-by-word by inference from the input
                  sequence. Common tasks for decoder-only models include generating text and answering questions.<br>• <em>Encoder-decoder</em>: Both understands input text and generates output text based on the input text. Common tasks for encoder-decoder
                  models include translation and summarization.</td>
              </tr>
              <tr>
                <td>Regional availability</td>
                <td>You can work with models that are available in the same IBM Cloud regional data center as your watsonx services.</td>
              </tr>
              <tr>
                <td>Supported programming languages</td>
                <td>Not all foundation models work well for programming use cases. If you are planning to create a solution that summarizes, converts, generates, or otherwise processes code, review which programming languages were included in a model's pretraining
                  data sets and fine-tuning activities to determine whether that model is a fit for your use case.</td>
              </tr>
            </tbody>
          </table>
        </section>
        <section id="section-learn-more">
          <h2 id="learn-more">Learn more</h2>
          <ul>
            <li><a href="fm-tokens.html">Tokens and tokenization</a></li>
            <li><a href="fm-model-parameters.html">Model parameters for prompting</a></li>
            <li><a href="fm-prompt-tips.html">Prompt tips</a></li>
            <li><a href="../getting-started/wml-plans.html">Watson Machine Learning plans</a></li>
            <li><a href="../getting-started/regional-datactr.html#data-centers">Regional availability for foundation models</a></li>
          </ul>
          <p><strong>Parent topic:</strong> <a href="fm-models.html">Supported foundation models</a></p>
        </section>
      </section>
    </article>
  </main>

<script type="text/javascript"  src="/DEWsG3/JOI980/yQyM/iRupUf/mVarA/YDJa4kXtLhb7/LwkITClvAg/Wgkg/WmBVIDs"></script><link rel="stylesheet" type="text/css"  href="/_sec/cp_challenge/sec-4-4.css">
                                        <script  src="/_sec/cp_challenge/sec-cpt-4-4.js" async defer></script>
                                        <div id="sec-overlay" style="display:none;">
                                        <div id="sec-container">
                                        </div>
                                      </div></body></html>